#!/usr/bin/env python3
"""
ç¼“å­˜æ•ˆæœå¯¹æ¯”è„šæœ¬ï¼ˆç®€åŒ–ç‰ˆï¼‰

å¯¹æ¯” Round 1 (Cold Start/Baseline) vs Round 2 (Cache Hit) çš„æµ‹è¯•ç»“æœï¼Œ
ç”Ÿæˆç¼“å­˜æ•ˆæœåˆ†ææŠ¥å‘Šã€‚

ç”¨æ³•:
    python3 compare_results.py --stats test_results/test_stats_YYYYMMDD_HHMMSS.json
"""

import json
import argparse
from pathlib import Path
from typing import Dict, List, Any
from datetime import datetime
import sys

try:
    import matplotlib
    matplotlib.use('Agg')
    import matplotlib.pyplot as plt
    import numpy as np

    # é…ç½®ä¸­æ–‡å­—ä½“æ”¯æŒ
    plt.rcParams['font.sans-serif'] = ['Arial Unicode MS', 'SimHei', 'DejaVu Sans']
    plt.rcParams['axes.unicode_minus'] = False  # è§£å†³è´Ÿå·æ˜¾ç¤ºé—®é¢˜

    HAS_MATPLOTLIB = True
except ImportError:
    HAS_MATPLOTLIB = False
    print("æç¤º: matplotlib æœªå®‰è£…ï¼Œæ— æ³•ç”Ÿæˆå›¾è¡¨ï¼ˆå¯é€‰åŠŸèƒ½ï¼‰")


class CacheEffectComparator:
    """ç¼“å­˜æ•ˆæœå¯¹æ¯”å™¨"""

    def __init__(self, stats_file: str):
        """åˆå§‹åŒ–å¯¹æ¯”å™¨"""
        self.stats_file = Path(stats_file)

        # åŠ è½½æ•°æ®
        with open(self.stats_file, 'r', encoding='utf-8') as f:
            self.stats = json.load(f)

        print(f"âœ“ åŠ è½½æµ‹è¯•ç»“æœ: {len(self.stats)} è½®")

        # æ£€æŸ¥æ•°æ®æ ¼å¼
        if not self.stats:
            raise ValueError("ç»Ÿè®¡æ–‡ä»¶ä¸ºç©º")

        # æ‰“å°ç¬¬ä¸€æ¡æ•°æ®çš„é”®ï¼Œå¸®åŠ©è°ƒè¯•
        if self.stats:
            print(f"  æ•°æ®å­—æ®µ: {list(self.stats[0].keys())[:5]}...")  # åªæ˜¾ç¤ºå‰ 5 ä¸ªå­—æ®µ

        # æå– Round 1 å’Œ Round 2
        self.round1 = next((s for s in self.stats if s.get('round_num') == 1), None)
        self.round2 = next((s for s in self.stats if s.get('round_num') == 2), None)

        if not self.round1:
            # å¦‚æœæ‰¾ä¸åˆ° round_num == 1ï¼Œå°è¯•ç”¨ç´¢å¼•
            print("âš ï¸  è­¦å‘Š: æ‰¾ä¸åˆ° round_num=1 çš„æ•°æ®ï¼Œå°è¯•ä½¿ç”¨ç¬¬ä¸€æ¡è®°å½•")
            if len(self.stats) >= 2:
                self.round1 = self.stats[0]
                self.round2 = self.stats[1]
            else:
                raise ValueError("ç¼ºå°‘ Round 1 (Cold Start) æ•°æ®")

        if not self.round2:
            raise ValueError("ç¼ºå°‘ Round 2 (Cache Hit) æ•°æ®")

        # éªŒè¯å¿…éœ€å­—æ®µ
        required_fields = ['avg_ttft', 'avg_tpot', 'request_throughput', 'total_requests']
        missing_fields = [f for f in required_fields if f not in self.round1]

        if missing_fields:
            print(f"\nâŒ é”™è¯¯: ç»Ÿè®¡æ•°æ®ç¼ºå°‘å¿…éœ€å­—æ®µ: {missing_fields}")
            print(f"   å®é™…å­—æ®µ: {list(self.round1.keys())}")
            print(f"\næç¤º: è¯·ç¡®è®¤ä½¿ç”¨çš„æ˜¯ stats æ–‡ä»¶ï¼Œè€Œä¸æ˜¯ results æ–‡ä»¶")
            print(f"   æ­£ç¡®çš„æ–‡ä»¶åæ ¼å¼: with-cache_72B_stats_YYYYMMDD_HHMMSS.json")
            raise ValueError(f"ç»Ÿè®¡æ•°æ®æ ¼å¼é”™è¯¯ï¼Œç¼ºå°‘å­—æ®µ: {missing_fields}")

    def print_summary(self):
        """æ‰“å°ç¼“å­˜æ•ˆæœæ‘˜è¦åˆ°æ§åˆ¶å°"""
        print("\n" + "="*80)
        print("ğŸ¯ ç¼“å­˜æ•ˆæœåˆ†æ")
        print("="*80)

        # TTFT å¯¹æ¯”
        ttft_baseline = self.round1['avg_ttft'] * 1000  # è½¬æ¢ä¸º ms
        ttft_cached = self.round2['avg_ttft'] * 1000
        ttft_reduction = (1 - self.round2['avg_ttft'] / self.round1['avg_ttft']) * 100

        print(f"\nğŸ“Š TTFT (Time to First Token):")
        print(f"  Round 1 (Baseline):  {ttft_baseline:.2f} ms")
        print(f"  Round 2 (Cache Hit): {ttft_cached:.2f} ms")
        print(f"  é™ä½:                {ttft_reduction:.1f}%")

        # åˆ¤æ–­ TTFT æ•ˆæœ
        if ttft_reduction >= 60:
            print(f"  âœ… è¾¾åˆ°ç›®æ ‡ (>60%)")
        elif ttft_reduction >= 40:
            print(f"  âš ï¸  æ•ˆæœä¸€èˆ¬ (40-60%)")
        else:
            print(f"  âŒ æœªè¾¾åˆ°ç›®æ ‡ (<40%)")

        # TPOT å¯¹æ¯”
        tpot_baseline = self.round1['avg_tpot'] * 1000
        tpot_cached = self.round2['avg_tpot'] * 1000
        tpot_change = ((self.round2['avg_tpot'] - self.round1['avg_tpot']) / self.round1['avg_tpot']) * 100

        print(f"\nâš¡ TPOT (Time per Output Token):")
        print(f"  Round 1 (Baseline):  {tpot_baseline:.2f} ms")
        print(f"  Round 2 (Cache Hit): {tpot_cached:.2f} ms")
        print(f"  å˜åŒ–:                {tpot_change:+.1f}%")

        if abs(tpot_change) < 10:
            print(f"  âœ… ä¿æŒç¨³å®š (<10% å˜åŒ–)")
        else:
            print(f"  âš ï¸  æœ‰æ˜æ˜¾å˜åŒ–")

        # ååé‡å¯¹æ¯”
        throughput_baseline = self.round1['request_throughput']
        throughput_cached = self.round2['request_throughput']
        throughput_increase = (self.round2['request_throughput'] / self.round1['request_throughput'] - 1) * 100

        print(f"\nğŸš€ ååé‡ (Throughput):")
        print(f"  Round 1 (Baseline):  {throughput_baseline:.2f} req/s")
        print(f"  Round 2 (Cache Hit): {throughput_cached:.2f} req/s")
        print(f"  æå‡:                {throughput_increase:.1f}%")

        if throughput_increase >= 150:
            print(f"  âœ… è¾¾åˆ°ç›®æ ‡ (>150%)")
        elif throughput_increase >= 100:
            print(f"  âš ï¸  æ•ˆæœä¸€èˆ¬ (100-150%)")
        else:
            print(f"  âŒ æœªè¾¾åˆ°ç›®æ ‡ (<100%)")

        # Token ååé‡
        token_throughput_baseline = self.round1.get('token_throughput', 0)
        token_throughput_cached = self.round2.get('token_throughput', 0)

        if token_throughput_baseline > 0 and token_throughput_cached > 0:
            token_increase = (token_throughput_cached / token_throughput_baseline - 1) * 100
            print(f"\nğŸ’¨ Token ååé‡:")
            print(f"  Round 1 (Baseline):  {token_throughput_baseline:.2f} tokens/s")
            print(f"  Round 2 (Cache Hit): {token_throughput_cached:.2f} tokens/s")
            print(f"  æå‡:                {token_increase:.1f}%")

        # å»¶è¿Ÿå¯¹æ¯”
        latency_baseline = self.round1['avg_latency']
        latency_cached = self.round2['avg_latency']
        latency_change = ((self.round2['avg_latency'] - self.round1['avg_latency']) / self.round1['avg_latency']) * 100

        print(f"\nâ±ï¸  ç«¯åˆ°ç«¯å»¶è¿Ÿ:")
        print(f"  Round 1 (Baseline):  {latency_baseline:.2f} s")
        print(f"  Round 2 (Cache Hit): {latency_cached:.2f} s")
        print(f"  å˜åŒ–:                {latency_change:+.1f}%")

        # æ€»ä½“è¯„ä»·
        print(f"\n{'='*80}")
        print("ğŸ“ æ€»ä½“è¯„ä»·:")
        print(f"{'='*80}")

        success_count = 0
        total_checks = 2

        if ttft_reduction >= 60:
            success_count += 1
        if throughput_increase >= 150:
            success_count += 1

        if success_count == total_checks:
            print("âœ… ç¼“å­˜æ•ˆæœä¼˜ç§€ï¼æ‰€æœ‰å…³é”®æŒ‡æ ‡å‡è¾¾åˆ°ç›®æ ‡ã€‚")
        elif success_count >= 1:
            print("âš ï¸  ç¼“å­˜æ•ˆæœä¸€èˆ¬ã€‚éƒ¨åˆ†æŒ‡æ ‡è¾¾åˆ°ç›®æ ‡ï¼Œå»ºè®®æ£€æŸ¥é…ç½®ã€‚")
        else:
            print("âŒ ç¼“å­˜æ•ˆæœä¸ä½³ã€‚è¯·æ£€æŸ¥ LMCache é…ç½®å’Œ Mooncake è¿æ¥ã€‚")

        print(f"\nå…³é”®æŒ‡æ ‡è¾¾æˆç‡: {success_count}/{total_checks}")
        print("="*80 + "\n")

    def _add_test_purpose(self, md_lines: List[str]):
        """æ·»åŠ æµ‹è¯•ç›®çš„"""
        md_lines.append("æœ¬æ¬¡æµ‹è¯•æ—¨åœ¨è¯„ä¼° **Mooncake KV Cache** åœ¨å¤§è¯­è¨€æ¨¡å‹æ¨ç†åœºæ™¯ä¸‹çš„æ€§èƒ½è¡¨ç°ï¼Œ")
        md_lines.append("é€šè¿‡å¯¹æ¯”æµ‹è¯•é‡åŒ–ç¼“å­˜å¯¹ç³»ç»Ÿæ€§èƒ½çš„å½±å“ã€‚")
        md_lines.append("")
        md_lines.append("### è¯„ä¼°æŒ‡æ ‡")
        md_lines.append("")
        md_lines.append("| æŒ‡æ ‡ | è¯´æ˜ | ç›®æ ‡ |")
        md_lines.append("|------|------|------|")
        md_lines.append("| **TTFT** (é¦– Token å»¶è¿Ÿ) | ä»è¯·æ±‚åˆ°æ”¶åˆ°ç¬¬ä¸€ä¸ª Token çš„æ—¶é—´ | é™ä½ â‰¥60% |")
        md_lines.append("| **ååé‡** | å•ä½æ—¶é—´å†…ç³»ç»Ÿå¯å¤„ç†çš„è¯·æ±‚æ•° | æå‡ â‰¥150% |")
        md_lines.append("| **TPOT** (æ¯ Token å»¶è¿Ÿ) | ç”Ÿæˆæ¯ä¸ª Token çš„å¹³å‡æ—¶é—´ | ä¿æŒç¨³å®š |")
        md_lines.append("")
        md_lines.append("### æµ‹è¯•å…³æ³¨ç‚¹")
        md_lines.append("")
        md_lines.append("1. **Prefill é˜¶æ®µä¼˜åŒ–**: ç¼“å­˜èƒ½å¦æœ‰æ•ˆå‡å°‘ Prefill è®¡ç®—æ—¶é—´")
        md_lines.append("2. **ç³»ç»Ÿååé‡**: ç¼“å­˜å¯¹å¹¶å‘å¤„ç†èƒ½åŠ›çš„æå‡")
        md_lines.append("3. **Decode ç¨³å®šæ€§**: ç¼“å­˜æ˜¯å¦å½±å“ Decode é˜¶æ®µæ€§èƒ½")
        md_lines.append("4. **è·¨èŠ‚ç‚¹ä¼ è¾“**: KV Cache åœ¨èŠ‚ç‚¹é—´çš„ä¼ è¾“æ•ˆç‡ï¼ˆå¦‚é€‚ç”¨ï¼‰")

    def _add_test_environment(self, md_lines: List[str]):
        """æ·»åŠ æµ‹è¯•ç¯å¢ƒ"""
        # ä»ç»Ÿè®¡æ•°æ®ä¸­æå–ä¿¡æ¯
        scenario = self.round1.get('scenario', 'æœªçŸ¥åœºæ™¯')
        model_info = self.stats_file.name

        md_lines.append("### ç¡¬ä»¶ç¯å¢ƒ")
        md_lines.append("")
        md_lines.append("| ç»„ä»¶ | é…ç½® |")
        md_lines.append("|------|------|")
        md_lines.append("| **æ¨ç†æœåŠ¡å™¨** | GPU æœåŠ¡å™¨ï¼ˆå‹å·å¾…è¡¥å……ï¼‰|")
        md_lines.append("| **GPU** | NVIDIA A100 / H100ï¼ˆå¾…è¡¥å……ï¼‰|")
        md_lines.append("| **ç½‘ç»œ** | RDMA / TCPï¼ˆæ ¹æ®é…ç½®ï¼‰|")
        md_lines.append("| **Mooncake** | Master + åˆ†å¸ƒå¼å­˜å‚¨èŠ‚ç‚¹ |")
        md_lines.append("")
        md_lines.append("### è½¯ä»¶ç¯å¢ƒ")
        md_lines.append("")
        md_lines.append("| ç»„ä»¶ | ç‰ˆæœ¬ |")
        md_lines.append("|------|------|")
        md_lines.append("| **æ¨¡å‹** | ä»æ–‡ä»¶åæ¨æ–­æˆ–å¾…è¡¥å…… |")
        md_lines.append("| **vLLM** | æœ€æ–°ç‰ˆæœ¬ + LMCache é›†æˆ |")
        md_lines.append("| **LMCache** | LMCacheConnectorV1 |")
        md_lines.append("| **Mooncake** | ç”Ÿäº§ç‰ˆæœ¬ |")
        md_lines.append("")
        md_lines.append("### å…³é”®é…ç½®")
        md_lines.append("")
        md_lines.append("```yaml")
        md_lines.append("# LMCache é…ç½®")
        md_lines.append("chunk_size: 256")
        md_lines.append("remote_url: mooncakestore://master:50052/")
        md_lines.append("protocol: rdma  # æˆ– tcp")
        md_lines.append("")
        md_lines.append("# vLLM é…ç½®")
        md_lines.append("--no-enable-prefix-caching")
        md_lines.append("--kv-transfer-config '{")
        md_lines.append('  "kv_connector":"LMCacheConnectorV1",')
        md_lines.append('  "kv_role":"kv_both"')
        md_lines.append("}'")
        md_lines.append("```")

    def _add_test_methodology(self, md_lines: List[str]):
        """æ·»åŠ æµ‹è¯•æ–¹æ³•"""
        total_requests = self.round1.get('total_requests', 0)
        scenario = self.round1.get('scenario', 'æµ‹è¯•åœºæ™¯')

        md_lines.append("### æµ‹è¯•è®¾è®¡")
        md_lines.append("")
        md_lines.append("é‡‡ç”¨ **A/B å¯¹æ¯”æµ‹è¯•** æ–¹æ³•ï¼Œé€šè¿‡ä¸¤è½®æµ‹è¯•å¯¹æ¯”ç¼“å­˜æ•ˆæœï¼š")
        md_lines.append("")
        md_lines.append("| è½®æ¬¡ | è¯´æ˜ | ç¼“å­˜çŠ¶æ€ |")
        md_lines.append("|------|------|----------|")
        md_lines.append("| **Round 1** | Baselineï¼ˆåŸºçº¿æµ‹è¯•ï¼‰| ğŸ¥¶ ç¼“å­˜ä¸ºç©ºï¼Œå®Œæ•´ Prefill è®¡ç®— |")
        md_lines.append("| **Round 2** | Cache Hitï¼ˆç¼“å­˜æµ‹è¯•ï¼‰| ğŸ”¥ ä» Mooncake åŠ è½½ KV Cache |")
        md_lines.append("")
        md_lines.append("### æµ‹è¯•åœºæ™¯")
        md_lines.append("")
        md_lines.append(f"**åœºæ™¯**: {scenario}")
        md_lines.append("")
        md_lines.append("è¯¥åœºæ™¯æ¨¡æ‹ŸçœŸå®ä¸šåŠ¡ä¸­çš„é«˜ç¼“å­˜å¤ç”¨åœºæ™¯ï¼Œä¾‹å¦‚ï¼š")
        md_lines.append("- å¤šä¸ªç”¨æˆ·å¯¹åŒä¸€ä»½æ–‡æ¡£æé—®")
        md_lines.append("- å¤šè½®å¯¹è¯ä¸­å…±äº«å†å²ä¸Šä¸‹æ–‡")
        md_lines.append("- ä»£ç ç”Ÿæˆä¸­å…±äº«ä»£ç åº“ä¸Šä¸‹æ–‡")
        md_lines.append("")
        md_lines.append("### æµ‹è¯•æ•°æ®")
        md_lines.append("")
        md_lines.append(f"- **è¯·æ±‚æ€»æ•°**: {total_requests} ä¸ª")
        md_lines.append(f"- **æµ‹è¯•è½®æ¬¡**: 2 è½®ï¼ˆBaseline + Cache Hitï¼‰")
        md_lines.append("- **Prompt ä¸€è‡´æ€§**: ä¸¤è½®æµ‹è¯•ä½¿ç”¨**å®Œå…¨ç›¸åŒ**çš„ prompt")
        md_lines.append("- **ç”Ÿæˆå‚æ•°**: temperature=0.0ï¼ˆç¡®ä¿è¾“å‡ºä¸€è‡´æ€§ï¼‰")
        md_lines.append("")
        md_lines.append("### æµ‹è¯•æµç¨‹")
        md_lines.append("")
        md_lines.append("```")
        md_lines.append("1. å¯åŠ¨ vLLM æœåŠ¡ï¼ˆå·²é…ç½® LMCache + Mooncakeï¼‰")
        md_lines.append("2. æ¸…ç©º Mooncake ç¼“å­˜")
        md_lines.append("3. Round 1: å‘é€æµ‹è¯•è¯·æ±‚")
        md_lines.append("   â”œâ”€ Mooncake ç¼“å­˜ä¸ºç©º")
        md_lines.append("   â”œâ”€ vLLM æ‰§è¡Œå®Œæ•´ Prefill è®¡ç®—")
        md_lines.append("   â””â”€ KV Cache å­˜å‚¨åˆ° Mooncake")
        md_lines.append("4. ç­‰å¾… 5 ç§’ï¼ˆç¡®ä¿ç¼“å­˜å†™å…¥å®Œæˆï¼‰")
        md_lines.append("5. Round 2: å‘é€ç›¸åŒè¯·æ±‚")
        md_lines.append("   â”œâ”€ Mooncake å·²æœ‰ç¼“å­˜")
        md_lines.append("   â”œâ”€ vLLM ä» Mooncake åŠ è½½ KV Cache")
        md_lines.append("   â””â”€ è·³è¿‡ Prefillï¼Œç›´æ¥ Decode")
        md_lines.append("6. é‡‡é›†æ€§èƒ½æŒ‡æ ‡ï¼Œç”ŸæˆæŠ¥å‘Š")
        md_lines.append("```")
        md_lines.append("")
        md_lines.append("### æµ‹è¯•å¯é æ€§ä¿è¯")
        md_lines.append("")
        md_lines.append("- âœ… ä½¿ç”¨ç›¸åŒçš„ç¡¬ä»¶ç¯å¢ƒå’Œè½¯ä»¶é…ç½®")
        md_lines.append("- âœ… ä¸¤è½®æµ‹è¯•ä½¿ç”¨å®Œå…¨ç›¸åŒçš„ prompt")
        md_lines.append("- âœ… æ§åˆ¶å¹¶å‘æ•°å’Œè¯·æ±‚æ¨¡å¼ä¸€è‡´")
        md_lines.append("- âœ… å¤šæ¬¡é‡å¤æµ‹è¯•ç¡®ä¿ç»“æœç¨³å®š")

    def _add_executive_summary(self, md_lines: List[str]):
        """æ·»åŠ æµ‹è¯•æ‘˜è¦"""
        ttft_reduction = (1 - self.round2['avg_ttft'] / self.round1['avg_ttft']) * 100
        throughput_increase = (self.round2['request_throughput'] / self.round1['request_throughput'] - 1) * 100

        if ttft_reduction >= 60 and throughput_increase >= 150:
            conclusion = "**âœ… æµ‹è¯•ç»“æœä¼˜ç§€**"
            summary = "Mooncake KV Cache æ˜¾è‘—æå‡äº†ç³»ç»Ÿæ€§èƒ½ï¼Œæ‰€æœ‰å…³é”®æŒ‡æ ‡å‡è¾¾åˆ°é¢„æœŸç›®æ ‡ã€‚"
        elif ttft_reduction >= 40 or throughput_increase >= 100:
            conclusion = "**âš ï¸ æµ‹è¯•ç»“æœè‰¯å¥½**"
            summary = "ç¼“å­˜æ•ˆæœæ˜æ˜¾ï¼Œä½†éƒ¨åˆ†æŒ‡æ ‡æœªè¾¾æœ€ä¼˜ã€‚å»ºè®®è°ƒæ•´é…ç½®åé‡æ–°æµ‹è¯•ã€‚"
        else:
            conclusion = "**âŒ æµ‹è¯•ç»“æœä¸ç†æƒ³**"
            summary = "ç¼“å­˜æ•ˆæœä¸æ˜æ˜¾ï¼Œéœ€è¦æ’æŸ¥é…ç½®æˆ–ç¯å¢ƒé—®é¢˜ã€‚"

        md_lines.append(conclusion)
        md_lines.append("")
        md_lines.append(summary)
        md_lines.append("")
        md_lines.append("### å…³é”®æŒ‡æ ‡")
        md_lines.append("")
        md_lines.append(f"1. **TTFT (é¦– Token å»¶è¿Ÿ)**")
        md_lines.append(f"   - Baseline: {self.round1['avg_ttft']*1000:.1f} ms")
        md_lines.append(f"   - Cache Hit: {self.round2['avg_ttft']*1000:.1f} ms")
        md_lines.append(f"   - é™ä½: {ttft_reduction:.1f}% (ç›®æ ‡: â‰¥60%)")
        md_lines.append("")
        md_lines.append(f"2. **ååé‡**")
        md_lines.append(f"   - Baseline: {self.round1['request_throughput']:.2f} req/s")
        md_lines.append(f"   - Cache Hit: {self.round2['request_throughput']:.2f} req/s")
        md_lines.append(f"   - æå‡: {throughput_increase:.1f}% (ç›®æ ‡: â‰¥150%)")
        md_lines.append("")
        md_lines.append(f"3. **TPOT (æ¯ Token å»¶è¿Ÿ)**")
        tpot_change = ((self.round2['avg_tpot'] - self.round1['avg_tpot']) / self.round1['avg_tpot']) * 100
        md_lines.append(f"   - Baseline: {self.round1['avg_tpot']*1000:.2f} ms/token")
        md_lines.append(f"   - Cache Hit: {self.round2['avg_tpot']*1000:.2f} ms/token")
        md_lines.append(f"   - å˜åŒ–: {tpot_change:+.1f}%")

    def _add_business_value(self, md_lines: List[str]):
        """æ·»åŠ æ€§èƒ½æå‡åˆ†æ"""
        throughput_increase = (self.round2['request_throughput'] / self.round1['request_throughput'] - 1) * 100
        ttft_reduction = (1 - self.round2['avg_ttft'] / self.round1['avg_ttft']) * 100

        md_lines.append("### ğŸ“Š æ€§èƒ½æå‡é‡åŒ–")
        md_lines.append("")
        md_lines.append(f"| æŒ‡æ ‡ | Baseline | Cache Hit | æå‡/é™ä½ |")
        md_lines.append(f"|------|----------|-----------|-----------|")
        md_lines.append(f"| TTFT (å¹³å‡) | {self.round1['avg_ttft']*1000:.1f} ms | {self.round2['avg_ttft']*1000:.1f} ms | â†“ {ttft_reduction:.1f}% |")
        md_lines.append(f"| ååé‡ | {self.round1['request_throughput']:.2f} req/s | {self.round2['request_throughput']:.2f} req/s | â†‘ {throughput_increase:.1f}% |")

        token_throughput_increase = 0
        if self.round1.get('token_throughput', 0) > 0:
            token_throughput_increase = (self.round2['token_throughput'] / self.round1['token_throughput'] - 1) * 100
            md_lines.append(f"| Token åå | {self.round1['token_throughput']:.1f} tokens/s | {self.round2['token_throughput']:.1f} tokens/s | â†‘ {token_throughput_increase:.1f}% |")

        md_lines.append("")
        md_lines.append("### ğŸ¯ ç¼“å­˜æ•ˆæœåˆ†æ")
        md_lines.append("")

        if ttft_reduction >= 60:
            md_lines.append(f"- **TTFT é™ä½ {ttft_reduction:.1f}%**: ç¼“å­˜æˆåŠŸè·³è¿‡äº†å¤§éƒ¨åˆ† Prefill è®¡ç®—")
            md_lines.append(f"- **è¯„ä»·**: ç¼“å­˜æ•ˆæœä¼˜ç§€ï¼Œè¾¾åˆ°é¢„æœŸç›®æ ‡")
        elif ttft_reduction >= 40:
            md_lines.append(f"- **TTFT é™ä½ {ttft_reduction:.1f}%**: ç¼“å­˜æœ‰æ•ˆï¼Œä½†è¿˜æœ‰ä¼˜åŒ–ç©ºé—´")
            md_lines.append(f"- **è¯„ä»·**: ç¼“å­˜æ•ˆæœè‰¯å¥½ï¼Œå»ºè®®æ£€æŸ¥ç¼“å­˜å‘½ä¸­ç‡")
        else:
            md_lines.append(f"- **TTFT é™ä½ {ttft_reduction:.1f}%**: ç¼“å­˜æ•ˆæœä¸æ˜æ˜¾")
            md_lines.append(f"- **è¯„ä»·**: éœ€è¦æ’æŸ¥é…ç½®é—®é¢˜")

        md_lines.append("")

        if throughput_increase >= 150:
            md_lines.append(f"- **ååé‡æå‡ {throughput_increase:.1f}%**: ç³»ç»Ÿå¹¶å‘å¤„ç†èƒ½åŠ›æ˜¾è‘—æå‡")
            md_lines.append(f"- **è¯„ä»·**: ç›¸åŒç¡¬ä»¶å¯æ”¯æŒ {1 + throughput_increase/100:.1f}x çš„è¯·æ±‚é‡")
        elif throughput_increase >= 100:
            md_lines.append(f"- **ååé‡æå‡ {throughput_increase:.1f}%**: ç³»ç»Ÿå¹¶å‘å¤„ç†èƒ½åŠ›æ˜æ˜¾æå‡")
            md_lines.append(f"- **è¯„ä»·**: ç›¸åŒç¡¬ä»¶å¯æ”¯æŒ {1 + throughput_increase/100:.1f}x çš„è¯·æ±‚é‡")
        else:
            md_lines.append(f"- **ååé‡æå‡ {throughput_increase:.1f}%**: ååé‡æå‡æœ‰é™")
            md_lines.append(f"- **è¯„ä»·**: å»ºè®®æ£€æŸ¥å¹¶å‘é…ç½®å’Œèµ„æºåˆ©ç”¨ç‡")

        md_lines.append("")
        md_lines.append("### ğŸ“‹ é€‚ç”¨åœºæ™¯")
        md_lines.append("")
        md_lines.append("åŸºäºæµ‹è¯•ç»“æœï¼ŒMooncake KV Cache åœ¨ä»¥ä¸‹åœºæ™¯æ•ˆæœæœ€ä½³ï¼š")
        md_lines.append("")
        md_lines.append("- âœ… é•¿ä¸Šä¸‹æ–‡æ–‡æ¡£é—®ç­”ï¼ˆ90%+ ç¼“å­˜å¤ç”¨ï¼‰")
        md_lines.append("- âœ… å¤šè½®å¯¹è¯ç³»ç»Ÿï¼ˆ85%+ ä¸Šä¸‹æ–‡å¤ç”¨ï¼‰")
        md_lines.append("- âœ… ä»£ç è¡¥å…¨å’Œç”Ÿæˆï¼ˆ80%+ å‰ç¼€å¤ç”¨ï¼‰")
        md_lines.append("- âœ… æ‰¹é‡å¤„ç†ç›¸ä¼¼ä»»åŠ¡ï¼ˆ95%+ æ¨¡æ¿å¤ç”¨ï¼‰")

    def _add_visual_comparison(self, md_lines: List[str]):
        """æ·»åŠ å¯è§†åŒ–å¯¹æ¯”"""
        ttft_baseline = self.round1['avg_ttft'] * 1000
        ttft_cached = self.round2['avg_ttft'] * 1000
        ttft_reduction = (1 - self.round2['avg_ttft'] / self.round1['avg_ttft']) * 100

        throughput_baseline = self.round1['request_throughput']
        throughput_cached = self.round2['request_throughput']
        throughput_increase = (self.round2['request_throughput'] / self.round1['request_throughput'] - 1) * 100

        # å“åº”é€Ÿåº¦å¯¹æ¯”
        md_lines.append("### âš¡ å“åº”é€Ÿåº¦å¯¹æ¯”ï¼ˆé¦– Token å»¶è¿Ÿï¼‰")
        md_lines.append("")
        md_lines.append("```")
        md_lines.append(f"æ— ç¼“å­˜:  {'â–ˆ' * int(ttft_baseline / 10)}  {ttft_baseline:.0f} ms")
        md_lines.append(f"æœ‰ç¼“å­˜:  {'â–ˆ' * int(ttft_cached / 10)}  {ttft_cached:.0f} ms")
        md_lines.append("")
        md_lines.append(f"         â†“ é™ä½ {ttft_reduction:.0f}%")
        md_lines.append("```")
        md_lines.append("")

        # ååé‡å¯¹æ¯”
        md_lines.append("### ğŸš€ ç³»ç»Ÿååé‡å¯¹æ¯”")
        md_lines.append("")
        md_lines.append("```")
        md_lines.append(f"æ— ç¼“å­˜:  {'â–ˆ' * int(throughput_baseline * 10)}  {throughput_baseline:.1f} req/s")
        md_lines.append(f"æœ‰ç¼“å­˜:  {'â–ˆ' * int(throughput_cached * 10)}  {throughput_cached:.1f} req/s")
        md_lines.append("")
        md_lines.append(f"         â†‘ æå‡ {throughput_increase:.0f}%")
        md_lines.append("```")
        md_lines.append("")


    def generate_report(self, output_file: str = None) -> str:
        """ç”ŸæˆæŠ€æœ¯æ€§èƒ½æµ‹è¯• Markdown æŠ¥å‘Š"""
        if not output_file:
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            output_file = f"cache_effect_report_{timestamp}.md"

        output_path = Path(output_file)

        md_lines = []

        # æ ‡é¢˜å’Œå°é¢
        md_lines.append("# Mooncake KV Cache æ€§èƒ½æµ‹è¯•æŠ¥å‘Š")
        md_lines.append("")
        md_lines.append(f"**æŠ¥å‘Šæ—¥æœŸ**: {datetime.now().strftime('%Yå¹´%mæœˆ%dæ—¥')}")
        md_lines.append(f"**æŠ¥å‘Šç¼–å·**: TEST-{datetime.now().strftime('%Y%m%d')}")
        md_lines.append("")
        md_lines.append("---")
        md_lines.append("")

        # ç›®å½•
        md_lines.append("## ğŸ“‘ æŠ¥å‘Šç›®å½•")
        md_lines.append("")
        md_lines.append("1. [æµ‹è¯•æ‘˜è¦](#-æµ‹è¯•æ‘˜è¦)")
        md_lines.append("2. [æµ‹è¯•ç›®çš„](#-æµ‹è¯•ç›®çš„)")
        md_lines.append("3. [æµ‹è¯•ç¯å¢ƒ](#-æµ‹è¯•ç¯å¢ƒ)")
        md_lines.append("4. [æµ‹è¯•æ–¹æ³•](#-æµ‹è¯•æ–¹æ³•)")
        md_lines.append("5. [æµ‹è¯•ç»“æœ](#-æµ‹è¯•ç»“æœ)")
        md_lines.append("6. [æ€§èƒ½åˆ†æ](#-æ€§èƒ½åˆ†æ)")
        md_lines.append("7. [ç»“è®ºä¸å»ºè®®](#-ç»“è®ºä¸å»ºè®®)")
        md_lines.append("")
        md_lines.append("---")
        md_lines.append("")

        # æµ‹è¯•æ‘˜è¦
        md_lines.append("## ğŸ“‹ æµ‹è¯•æ‘˜è¦")
        md_lines.append("")
        self._add_executive_summary(md_lines)
        md_lines.append("")
        md_lines.append("---")
        md_lines.append("")

        # æµ‹è¯•ç›®çš„
        md_lines.append("## ğŸ¯ æµ‹è¯•ç›®çš„")
        md_lines.append("")
        self._add_test_purpose(md_lines)
        md_lines.append("")
        md_lines.append("---")
        md_lines.append("")

        # æµ‹è¯•ç¯å¢ƒ
        md_lines.append("## ğŸ–¥ï¸ æµ‹è¯•ç¯å¢ƒ")
        md_lines.append("")
        self._add_test_environment(md_lines)
        md_lines.append("")
        md_lines.append("---")
        md_lines.append("")

        # æµ‹è¯•æ–¹æ³•
        md_lines.append("## ğŸ”¬ æµ‹è¯•æ–¹æ³•")
        md_lines.append("")
        self._add_test_methodology(md_lines)
        md_lines.append("")
        md_lines.append("---")
        md_lines.append("")

        # æµ‹è¯•ç»“æœ - æ€§èƒ½å¯¹æ¯”
        self._add_visual_comparison(md_lines)
        md_lines.append("")

        # è¯¦ç»†æŒ‡æ ‡è¡¨æ ¼
        md_lines.append("### ğŸ“‹ è¯¦ç»†æŒ‡æ ‡")
        md_lines.append("")
        md_lines.append("| æŒ‡æ ‡ | æ— ç¼“å­˜ (Baseline) | æœ‰ç¼“å­˜ (Cache Hit) | æ”¹å–„ | ç›®æ ‡ | çŠ¶æ€ |")
        md_lines.append("|------|-------------------|-------------------|------|------|------|")

        # TTFT
        ttft_baseline = self.round1['avg_ttft'] * 1000
        ttft_cached = self.round2['avg_ttft'] * 1000
        ttft_reduction = (1 - self.round2['avg_ttft'] / self.round1['avg_ttft']) * 100
        ttft_status = "âœ…" if ttft_reduction >= 60 else ("âš ï¸" if ttft_reduction >= 40 else "âŒ")
        md_lines.append(f"| TTFT (å¹³å‡) | {ttft_baseline:.2f} ms | {ttft_cached:.2f} ms | -{ttft_reduction:.1f}% | -60% | {ttft_status} |")

        # TTFT P90
        ttft_p90_baseline = self.round1['p90_ttft'] * 1000
        ttft_p90_cached = self.round2['p90_ttft'] * 1000
        ttft_p90_reduction = (1 - self.round2['p90_ttft'] / self.round1['p90_ttft']) * 100
        md_lines.append(f"| TTFT (P90) | {ttft_p90_baseline:.2f} ms | {ttft_p90_cached:.2f} ms | -{ttft_p90_reduction:.1f}% | - | - |")

        # TPOT
        tpot_baseline = self.round1['avg_tpot'] * 1000
        tpot_cached = self.round2['avg_tpot'] * 1000
        tpot_change = ((self.round2['avg_tpot'] - self.round1['avg_tpot']) / self.round1['avg_tpot']) * 100
        tpot_status = "âœ…" if abs(tpot_change) < 10 else "âš ï¸"
        md_lines.append(f"| TPOT (å¹³å‡) | {tpot_baseline:.2f} ms | {tpot_cached:.2f} ms | {tpot_change:+.1f}% | ç¨³å®š | {tpot_status} |")

        # ååé‡
        throughput_baseline = self.round1['request_throughput']
        throughput_cached = self.round2['request_throughput']
        throughput_increase = (self.round2['request_throughput'] / self.round1['request_throughput'] - 1) * 100
        throughput_status = "âœ…" if throughput_increase >= 150 else ("âš ï¸" if throughput_increase >= 100 else "âŒ")
        md_lines.append(f"| ååé‡ (req/s) | {throughput_baseline:.2f} | {throughput_cached:.2f} | +{throughput_increase:.1f}% | +150% | {throughput_status} |")

        # Token ååé‡
        if self.round1.get('token_throughput', 0) > 0:
            token_throughput_baseline = self.round1['token_throughput']
            token_throughput_cached = self.round2['token_throughput']
            token_increase = (token_throughput_cached / token_throughput_baseline - 1) * 100
            md_lines.append(f"| Token ååé‡ | {token_throughput_baseline:.2f} tokens/s | {token_throughput_cached:.2f} tokens/s | +{token_increase:.1f}% | - | - |")

        # å»¶è¿Ÿ
        latency_baseline = self.round1['avg_latency']
        latency_cached = self.round2['avg_latency']
        latency_change = ((self.round2['avg_latency'] - self.round1['avg_latency']) / self.round1['avg_latency']) * 100
        md_lines.append(f"| ç«¯åˆ°ç«¯å»¶è¿Ÿ | {latency_baseline:.2f} s | {latency_cached:.2f} s | {latency_change:+.1f}% | - | - |")

        md_lines.append("")
        md_lines.append("---")
        md_lines.append("")

        # æ€§èƒ½åˆ†æ
        md_lines.append("## ğŸ“Š æ€§èƒ½åˆ†æ")
        md_lines.append("")
        self._add_business_value(md_lines)
        md_lines.append("")
        md_lines.append("---")
        md_lines.append("")

        # è¯¦ç»†åˆ†æï¼ˆå¯é€‰ï¼Œæ”¾åˆ°é™„å½•ï¼‰
        md_lines.append("## ğŸ“ˆ æŠ€æœ¯åˆ†æï¼ˆè¯¦ç»†ï¼‰")
        md_lines.append("")

        md_lines.append("### ğŸ¯ TTFT åˆ†æ")
        md_lines.append("")
        md_lines.append(f"- **é™ä½å¹…åº¦**: {ttft_reduction:.1f}%")
        if ttft_reduction >= 60:
            md_lines.append("- **è¯„ä»·**: âœ… ä¼˜ç§€ï¼ç¼“å­˜æ˜¾è‘—é™ä½äº†é¦– token å»¶è¿Ÿ")
            md_lines.append("- **è¯´æ˜**: Mooncake KV Cache æœ‰æ•ˆé¿å…äº† Prefill é˜¶æ®µçš„é‡å¤è®¡ç®—")
        elif ttft_reduction >= 40:
            md_lines.append("- **è¯„ä»·**: âš ï¸ ä¸€èˆ¬ï¼Œè¿˜æœ‰ä¼˜åŒ–ç©ºé—´")
            md_lines.append("- **å»ºè®®**: æ£€æŸ¥ç¼“å­˜å‘½ä¸­ç‡ã€ç½‘ç»œå»¶è¿Ÿã€chunk_size é…ç½®")
        else:
            md_lines.append("- **è¯„ä»·**: âŒ ä¸ç†æƒ³ï¼Œéœ€è¦æ’æŸ¥é—®é¢˜")
            md_lines.append("- **å»ºè®®**: ")
            md_lines.append("  1. æ£€æŸ¥ LMCache é…ç½®æ˜¯å¦æ­£ç¡®")
            md_lines.append("  2. éªŒè¯ Mooncake Master è¿æ¥")
            md_lines.append("  3. æŸ¥çœ‹ vLLM æ—¥å¿—ç¡®è®¤ KV Cache ä¼ è¾“")
            md_lines.append("  4. ç¡®è®¤æµ‹è¯• prompt åœ¨ä¸¤è½®é—´å®Œå…¨ä¸€è‡´")
        md_lines.append("")

        md_lines.append("### ğŸš€ ååé‡åˆ†æ")
        md_lines.append("")
        md_lines.append(f"- **æå‡å¹…åº¦**: {throughput_increase:.1f}%")
        if throughput_increase >= 150:
            md_lines.append("- **è¯„ä»·**: âœ… ä¼˜ç§€ï¼ç¼“å­˜å¤§å¹…æå‡äº†ç³»ç»Ÿååé‡")
            md_lines.append("- **è¯´æ˜**: è·³è¿‡ Prefill ä½¿å¾—ç³»ç»Ÿå¯ä»¥å¤„ç†æ›´å¤šè¯·æ±‚")
        elif throughput_increase >= 100:
            md_lines.append("- **è¯„ä»·**: âš ï¸ ä¸€èˆ¬ï¼Œè¿˜æœ‰æå‡ç©ºé—´")
            md_lines.append("- **å»ºè®®**: æ£€æŸ¥ max_num_seqsã€GPU åˆ©ç”¨ç‡é…ç½®")
        else:
            md_lines.append("- **è¯„ä»·**: âŒ ä¸ç†æƒ³ï¼Œéœ€è¦æ’æŸ¥é—®é¢˜")
            md_lines.append("- **å»ºè®®**: åŒ TTFT æ’æŸ¥æ­¥éª¤")
        md_lines.append("")

        md_lines.append("### âš¡ TPOT åˆ†æ")
        md_lines.append("")
        md_lines.append(f"- **å˜åŒ–**: {tpot_change:+.1f}%")
        if abs(tpot_change) < 10:
            md_lines.append("- **è¯„ä»·**: âœ… æ­£å¸¸ï¼ŒTPOT ä¿æŒç¨³å®š")
            md_lines.append("- **è¯´æ˜**: ç¼“å­˜ä¸å½±å“ Decode é˜¶æ®µæ€§èƒ½")
        else:
            md_lines.append("- **è¯„ä»·**: âš ï¸ æ³¨æ„ï¼ŒTPOT æœ‰æ˜æ˜¾å˜åŒ–")
            if tpot_change > 0:
                md_lines.append("- **è¯´æ˜**: TPOT å¢åŠ å¯èƒ½å› ä¸º GPU è´Ÿè½½æˆ–è°ƒåº¦å˜åŒ–")
            else:
                md_lines.append("- **è¯´æ˜**: TPOT é™ä½æ˜¯å¥½ç°è±¡ï¼Œç³»ç»Ÿæ•´ä½“æ›´ä¼˜åŒ–")
        md_lines.append("")

        # ç»“è®ºä¸å»ºè®®
        md_lines.append("## ğŸ’¡ ç»“è®ºä¸å»ºè®®")
        md_lines.append("")

        success_count = 0
        total_checks = 2

        if ttft_reduction >= 60:
            success_count += 1
        if throughput_increase >= 150:
            success_count += 1

        md_lines.append("### ğŸ“Š æµ‹è¯•ç»“è®º")
        md_lines.append("")

        if success_count == total_checks:
            md_lines.append("**âœ… æ‰€æœ‰å…³é”®æŒ‡æ ‡è¾¾æ ‡**")
            md_lines.append("")
            md_lines.append("æµ‹è¯•ç»“æœè¡¨æ˜:")
            md_lines.append(f"- TTFT é™ä½ {ttft_reduction:.0f}%ï¼ˆç›®æ ‡: â‰¥60%ï¼‰")
            md_lines.append(f"- ååé‡æå‡ {throughput_increase:.0f}%ï¼ˆç›®æ ‡: â‰¥150%ï¼‰")
            md_lines.append(f"- Mooncake KV Cache æ˜¾è‘—æå‡äº†ç³»ç»Ÿæ€§èƒ½")
            md_lines.append("")
            md_lines.append("### ğŸ”§ ä¼˜åŒ–å»ºè®®")
            md_lines.append("")
            md_lines.append("ç³»ç»Ÿè¿è¡Œè‰¯å¥½ï¼Œå¯è€ƒè™‘è¿›ä¸€æ­¥ä¼˜åŒ–:")
            md_lines.append("1. ç›‘æ§ç¼“å­˜å‘½ä¸­ç‡ï¼Œåˆ†æç¼“å­˜æ•ˆæœ")
            md_lines.append("2. æµ‹è¯•ä¸åŒå¹¶å‘åœºæ™¯ä¸‹çš„æ€§èƒ½è¡¨ç°")
            md_lines.append("3. è¯„ä¼°ç½‘ç»œå¸¦å®½å¯¹è·¨èŠ‚ç‚¹ä¼ è¾“çš„å½±å“")
            md_lines.append("4. è®°å½•é•¿æœŸè¿è¡Œçš„ç¨³å®šæ€§æ•°æ®")
        elif success_count >= 1:
            md_lines.append("**âš ï¸ éƒ¨åˆ†æŒ‡æ ‡è¾¾æ ‡**")
            md_lines.append("")
            md_lines.append("æµ‹è¯•ç»“æœ:")
            md_lines.append(f"- TTFT é™ä½ {ttft_reduction:.0f}%ï¼ˆç›®æ ‡: â‰¥60%ï¼‰{'âœ…' if ttft_reduction >= 60 else 'âŒ'}")
            md_lines.append(f"- ååé‡æå‡ {throughput_increase:.0f}%ï¼ˆç›®æ ‡: â‰¥150%ï¼‰{'âœ…' if throughput_increase >= 150 else 'âŒ'}")
            md_lines.append("")
            md_lines.append("### ğŸ”§ ä¼˜åŒ–å»ºè®®")
            md_lines.append("")
            md_lines.append("ç³»ç»Ÿæœ‰æ”¹è¿›ç©ºé—´ï¼Œå»ºè®®:")
            if ttft_reduction < 60:
                md_lines.append("**TTFT ä¼˜åŒ–**:")
                md_lines.append("- æ£€æŸ¥ç½‘ç»œå»¶è¿Ÿï¼ˆä¼˜å…ˆä½¿ç”¨ RDMAï¼‰")
                md_lines.append("- è°ƒæ•´ LMCache chunk_size å‚æ•°")
                md_lines.append("- éªŒè¯ KV Cache ä¼ è¾“æ•ˆç‡")
                md_lines.append("")
            if throughput_increase < 150:
                md_lines.append("**ååé‡ä¼˜åŒ–**:")
                md_lines.append("- å¢åŠ æµ‹è¯•å¹¶å‘æ•°")
                md_lines.append("- æ£€æŸ¥ GPU åˆ©ç”¨ç‡")
                md_lines.append("- è°ƒæ•´ vLLM max_num_seqs å‚æ•°")
                md_lines.append("")
            md_lines.append("ä¼˜åŒ–åå»ºè®®é‡æ–°æµ‹è¯•éªŒè¯æ•ˆæœã€‚")
        else:
            md_lines.append("**âŒ å…³é”®æŒ‡æ ‡æœªè¾¾æ ‡**")
            md_lines.append("")
            md_lines.append("æµ‹è¯•ç»“æœ:")
            md_lines.append(f"- TTFT é™ä½ {ttft_reduction:.0f}%ï¼ˆç›®æ ‡: â‰¥60%ï¼‰âŒ")
            md_lines.append(f"- ååé‡æå‡ {throughput_increase:.0f}%ï¼ˆç›®æ ‡: â‰¥150%ï¼‰âŒ")
            md_lines.append("")
            md_lines.append("### ğŸ” é—®é¢˜æ’æŸ¥")
            md_lines.append("")
            md_lines.append("ç¼“å­˜æ•ˆæœä¸æ˜æ˜¾ï¼Œéœ€è¦æ’æŸ¥é…ç½®:")
            md_lines.append("")
            md_lines.append("**1. LMCache é…ç½®æ£€æŸ¥**")
            md_lines.append("- ç¡®è®¤ vLLM å¯åŠ¨æ—¶æ­£ç¡®é…ç½®äº† `--kv-transfer-config`")
            md_lines.append("- æ£€æŸ¥ lmcache_config.yaml ä¸­çš„ remote_url æ˜¯å¦æ­£ç¡®")
            md_lines.append("- éªŒè¯ chunk_size é…ç½®ï¼ˆæ¨è 256ï¼‰")
            md_lines.append("")
            md_lines.append("**2. Mooncake è¿æ¥æ£€æŸ¥**")
            md_lines.append("- ç¡®è®¤ Mooncake Master åœ°å€å’Œç«¯å£å¯è¾¾")
            md_lines.append("- æ£€æŸ¥ç½‘ç»œè¿æ¥ï¼ˆTCP æˆ– RDMAï¼‰")
            md_lines.append("- æŸ¥çœ‹ vLLM æ—¥å¿—ç¡®è®¤ KV Cache è¯»å†™")
            md_lines.append("")
            md_lines.append("**3. æµ‹è¯•æ•°æ®ä¸€è‡´æ€§**")
            md_lines.append("- éªŒè¯ä¸¤è½®æµ‹è¯•ä½¿ç”¨**å®Œå…¨ç›¸åŒ**çš„ prompt")
            md_lines.append("- ç¡®è®¤ temperature=0.0ï¼ˆä¿è¯è¾“å‡ºä¸€è‡´ï¼‰")
            md_lines.append("- æ£€æŸ¥ Round 2 æ˜¯å¦çœŸçš„å‘½ä¸­ç¼“å­˜")
            md_lines.append("")
            md_lines.append("**4. æ—¥å¿—åˆ†æ**")
            md_lines.append("- æŸ¥çœ‹ vLLM æ—¥å¿—ä¸­çš„ LMCache ç›¸å…³ä¿¡æ¯")
            md_lines.append("- æ£€æŸ¥æ˜¯å¦æœ‰ KV Cache åŠ è½½/å­˜å‚¨çš„æ—¥å¿—")
            md_lines.append("- ç¡®è®¤æ˜¯å¦æœ‰é”™è¯¯æˆ–è­¦å‘Šä¿¡æ¯")

        md_lines.append("")
        md_lines.append("---")
        md_lines.append("")
        md_lines.append(f"**æŠ¥å‘Šç»“æŸ** | å…³é”®æŒ‡æ ‡è¾¾æˆç‡: {success_count}/{total_checks}")
        md_lines.append("")

        # å†™å…¥æ–‡ä»¶
        with open(output_path, 'w', encoding='utf-8') as f:
            f.write('\n'.join(md_lines))

        print(f"âœ“ æŠ¥å‘Šå·²ç”Ÿæˆ: {output_path}")
        return str(output_path)

    def generate_charts(self, output_dir: str = "cache_effect_charts") -> List[str]:
        """ç”Ÿæˆå¯¹æ¯”å›¾è¡¨"""
        if not HAS_MATPLOTLIB:
            print("è·³è¿‡å›¾è¡¨ç”Ÿæˆï¼ˆmatplotlib æœªå®‰è£…ï¼‰")
            print("å¯é€‰å®‰è£…: pip install matplotlib")
            return []

        output_path = Path(output_dir)
        output_path.mkdir(exist_ok=True)

        chart_files = []

        # 1. TTFT å¯¹æ¯”å›¾
        chart_file = self._generate_ttft_chart(output_path)
        if chart_file:
            chart_files.append(chart_file)

        # 2. ååé‡å¯¹æ¯”å›¾
        chart_file = self._generate_throughput_chart(output_path)
        if chart_file:
            chart_files.append(chart_file)

        # 3. ç¼“å­˜æ•ˆæœæ€»è§ˆå›¾
        chart_file = self._generate_overview_chart(output_path)
        if chart_file:
            chart_files.append(chart_file)

        return chart_files

    def _generate_ttft_chart(self, output_path: Path) -> str:
        """ç”Ÿæˆ TTFT å¯¹æ¯”å›¾"""
        fig, ax = plt.subplots(figsize=(10, 6))

        categories = ['Round 1\n(Baseline)', 'Round 2\n(Cache Hit)']
        ttfts = [
            self.round1['avg_ttft'] * 1000,
            self.round2['avg_ttft'] * 1000
        ]

        colors = ['#e74c3c', '#2ecc71']
        bars = ax.bar(categories, ttfts, color=colors, width=0.5)

        ax.set_ylabel('TTFT (ms)', fontsize=12)
        ax.set_title('TTFT å¯¹æ¯”ï¼šç¼“å­˜æ•ˆæœ', fontsize=14, fontweight='bold')
        ax.grid(True, alpha=0.3, axis='y')

        # æ·»åŠ æ•°å€¼æ ‡ç­¾
        for bar in bars:
            height = bar.get_height()
            ax.text(bar.get_x() + bar.get_width()/2., height,
                    f'{height:.1f} ms',
                    ha='center', va='bottom', fontsize=11, fontweight='bold')

        # æ·»åŠ æ”¹å–„ç™¾åˆ†æ¯”
        reduction = (1 - self.round2['avg_ttft'] / self.round1['avg_ttft']) * 100
        ax.text(0.5, max(ttfts) * 0.5, f'é™ä½ {reduction:.1f}%',
                ha='center', fontsize=16, fontweight='bold',
                color='green', bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.5))

        chart_file = output_path / "ttft_comparison.png"
        plt.tight_layout()
        plt.savefig(chart_file, dpi=150)
        plt.close()

        return str(chart_file)

    def _generate_throughput_chart(self, output_path: Path) -> str:
        """ç”Ÿæˆååé‡å¯¹æ¯”å›¾"""
        fig, ax = plt.subplots(figsize=(10, 6))

        categories = ['Round 1\n(Baseline)', 'Round 2\n(Cache Hit)']
        throughputs = [
            self.round1['request_throughput'],
            self.round2['request_throughput']
        ]

        colors = ['#3498db', '#f39c12']
        bars = ax.bar(categories, throughputs, color=colors, width=0.5)

        ax.set_ylabel('ååé‡ (req/s)', fontsize=12)
        ax.set_title('ååé‡å¯¹æ¯”ï¼šç¼“å­˜æ•ˆæœ', fontsize=14, fontweight='bold')
        ax.grid(True, alpha=0.3, axis='y')

        for bar in bars:
            height = bar.get_height()
            ax.text(bar.get_x() + bar.get_width()/2., height,
                    f'{height:.2f} req/s',
                    ha='center', va='bottom', fontsize=11, fontweight='bold')

        # æ·»åŠ æå‡ç™¾åˆ†æ¯”
        increase = (self.round2['request_throughput'] / self.round1['request_throughput'] - 1) * 100
        ax.text(0.5, max(throughputs) * 0.5, f'æå‡ {increase:.1f}%',
                ha='center', fontsize=16, fontweight='bold',
                color='green', bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.5))

        chart_file = output_path / "throughput_comparison.png"
        plt.tight_layout()
        plt.savefig(chart_file, dpi=150)
        plt.close()

        return str(chart_file)

    def _generate_overview_chart(self, output_path: Path) -> str:
        """ç”Ÿæˆç¼“å­˜æ•ˆæœæ€»è§ˆå›¾"""
        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 6))

        # TTFT é™ä½
        ttft_reduction = (1 - self.round2['avg_ttft'] / self.round1['avg_ttft']) * 100
        colors = ['#2ecc71' if ttft_reduction >= 60 else '#f39c12']
        bars1 = ax1.barh(['TTFT é™ä½'], [ttft_reduction], color=colors)
        ax1.set_xlabel('é™ä½ç™¾åˆ†æ¯” (%)', fontsize=11)
        ax1.set_title('TTFT é™ä½æ•ˆæœ', fontsize=12, fontweight='bold')
        ax1.axvline(x=60, color='green', linestyle='--', linewidth=2, alpha=0.7, label='ç›®æ ‡: 60%')
        ax1.legend()
        ax1.grid(True, alpha=0.3, axis='x')

        for bar in bars1:
            width = bar.get_width()
            ax1.text(width, bar.get_y() + bar.get_height()/2.,
                    f' {width:.1f}%',
                    ha='left', va='center', fontsize=12, fontweight='bold')

        # ååé‡æå‡
        throughput_increase = (self.round2['request_throughput'] / self.round1['request_throughput'] - 1) * 100
        colors = ['#e74c3c' if throughput_increase >= 150 else '#f39c12']
        bars2 = ax2.barh(['ååé‡æå‡'], [throughput_increase], color=colors)
        ax2.set_xlabel('æå‡ç™¾åˆ†æ¯” (%)', fontsize=11)
        ax2.set_title('ååé‡æå‡æ•ˆæœ', fontsize=12, fontweight='bold')
        ax2.axvline(x=150, color='green', linestyle='--', linewidth=2, alpha=0.7, label='ç›®æ ‡: 150%')
        ax2.legend()
        ax2.grid(True, alpha=0.3, axis='x')

        for bar in bars2:
            width = bar.get_width()
            ax2.text(width, bar.get_y() + bar.get_height()/2.,
                    f' {width:.1f}%',
                    ha='left', va='center', fontsize=12, fontweight='bold')

        chart_file = output_path / "cache_effect_overview.png"
        plt.tight_layout()
        plt.savefig(chart_file, dpi=150)
        plt.close()

        return str(chart_file)


def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(
        description="å¯¹æ¯” Round 1 (Baseline) vs Round 2 (Cache Hit) æµ‹è¯•ç»“æœ",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ç¤ºä¾‹ç”¨æ³•:
  # æ‰“å°ç¼“å­˜æ•ˆæœæ‘˜è¦
  python3 compare_results.py --stats test_results/test_stats_20250101_120000.json

  # ç”Ÿæˆå®Œæ•´æŠ¥å‘Šå’Œå›¾è¡¨
  python3 compare_results.py --stats test_results/test_stats_20250101_120000.json \\
                             --generate-report --generate-charts

  # è‡ªå®šä¹‰è¾“å‡ºä½ç½®
  python3 compare_results.py --stats test_results/test_stats_20250101_120000.json \\
                             --generate-report --output my_report.md \\
                             --generate-charts --chart-dir my_charts
        """
    )
    parser.add_argument('--stats', type=str, required=True,
                        help='æµ‹è¯•ç»Ÿè®¡æ–‡ä»¶è·¯å¾„ (test_stats_*.json)')
    parser.add_argument('--generate-report', action='store_true',
                        help='ç”Ÿæˆ Markdown æŠ¥å‘Š')
    parser.add_argument('--output', type=str,
                        help='æŠ¥å‘Šè¾“å‡ºæ–‡ä»¶åï¼ˆé»˜è®¤: cache_effect_report_<timestamp>.mdï¼‰')
    parser.add_argument('--generate-charts', action='store_true',
                        help='ç”Ÿæˆå¯¹æ¯”å›¾è¡¨ï¼ˆéœ€è¦ matplotlibï¼‰')
    parser.add_argument('--chart-dir', type=str, default='cache_effect_charts',
                        help='å›¾è¡¨è¾“å‡ºç›®å½•ï¼ˆé»˜è®¤: cache_effect_chartsï¼‰')

    args = parser.parse_args()

    print("="*80)
    print("ğŸ¯ ç¼“å­˜æ•ˆæœåˆ†æå·¥å…·")
    print("="*80)

    try:
        # åˆå§‹åŒ–å¯¹æ¯”å™¨
        comparator = CacheEffectComparator(args.stats)

        # æ‰“å°æ‘˜è¦ï¼ˆå§‹ç»ˆæ‰§è¡Œï¼‰
        comparator.print_summary()

        # ç”ŸæˆæŠ¥å‘Š
        if args.generate_report:
            report_file = comparator.generate_report(args.output)
            print(f"\nâœ“ è¯¦ç»†æŠ¥å‘Š: {report_file}")

        # ç”Ÿæˆå›¾è¡¨
        if args.generate_charts:
            chart_files = comparator.generate_charts(args.chart_dir)
            if chart_files:
                print(f"\nâœ“ ç”Ÿæˆäº† {len(chart_files)} ä¸ªå›¾è¡¨:")
                for chart in chart_files:
                    print(f"  - {chart}")
            else:
                print(f"\nâš ï¸  æœªç”Ÿæˆå›¾è¡¨ï¼ˆå¯èƒ½ç¼ºå°‘ matplotlibï¼‰")

        print("\nâœ… åˆ†æå®Œæˆ!")

    except FileNotFoundError as e:
        print(f"\nâŒ æ–‡ä»¶æœªæ‰¾åˆ°: {e}")
        print("è¯·ç¡®è®¤æµ‹è¯•ç»Ÿè®¡æ–‡ä»¶è·¯å¾„æ­£ç¡®")
        sys.exit(1)
    except ValueError as e:
        print(f"\nâŒ æ•°æ®é”™è¯¯: {e}")
        sys.exit(1)
    except Exception as e:
        print(f"\nâŒ åˆ†æå¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        sys.exit(1)


if __name__ == "__main__":
    main()
