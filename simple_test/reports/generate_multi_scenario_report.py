#!/usr/bin/env python3
"""
å¤šåœºæ™¯æµ‹è¯•ç»“æœæ±‡æ€»è„šæœ¬

æ”¯æŒå¤šä¸ªæµ‹è¯•åœºæ™¯çš„ç»“æœæ±‡æ€»ï¼Œç”Ÿæˆç»Ÿä¸€çš„è¡¨æ ¼å’Œå›¾è¡¨ã€‚

ç”¨æ³•:
    python3 generate_multi_scenario_report.py \
        --scenario "è…¾è®¯äº‘-å•æœº-Qwen2.5-72B" --stats test_results/qwen_single_stats.json \
        --scenario "è…¾è®¯äº‘-è·¨èŠ‚ç‚¹-Qwen2.5-72B" --stats test_results/qwen_cross_stats.json \
        --scenario "ç«å±±äº‘-å•æœº-Deepseek-R1" --stats test_results/deepseek_single_stats.json \
        --output report.md
"""

import json
import argparse
from pathlib import Path
from typing import Dict, List, Any, Tuple
from datetime import datetime
import sys

try:
    import matplotlib
    matplotlib.use('Agg')
    import matplotlib.pyplot as plt
    import numpy as np

    # é…ç½®ä¸­æ–‡å­—ä½“æ”¯æŒ
    plt.rcParams['font.sans-serif'] = ['Arial Unicode MS', 'SimHei', 'DejaVu Sans']
    plt.rcParams['axes.unicode_minus'] = False  # è§£å†³è´Ÿå·æ˜¾ç¤ºé—®é¢˜

    HAS_MATPLOTLIB = True
except ImportError:
    HAS_MATPLOTLIB = False
    print("æç¤º: matplotlib æœªå®‰è£…ï¼Œæ— æ³•ç”Ÿæˆå›¾è¡¨")
    print("å®‰è£…: pip install matplotlib")


class MultiScenarioReporter:
    """å¤šåœºæ™¯æµ‹è¯•æŠ¥å‘Šç”Ÿæˆå™¨"""

    def __init__(self):
        self.scenarios = []  # List of (name, stats_data)

        # ä¸­è‹±æ–‡æ ‡ç­¾æ˜ å°„
        self.label_translation = {
            'å•èŠ‚ç‚¹': 'Single',
            'è·¨èŠ‚ç‚¹': 'Cross',
            'å¤šè½®': 'Multi',
            'é•¿æ–‡æœ¬': 'Long',
            'å¤šè½®å¯¹è¯': 'Multi-Turn',
            'é•¿æ–‡æœ¬å¯¹è¯': 'Long-Text',
            'è…¾è®¯äº‘': 'Tencent',
            'ç«å±±äº‘': 'Volcano',
            'é˜¿é‡Œäº‘': 'Alibaba',
        }

    def _translate_label(self, label: str) -> str:
        """å°†ä¸­æ–‡æ ‡ç­¾ç¿»è¯‘ä¸ºè‹±æ–‡"""
        for zh, en in self.label_translation.items():
            label = label.replace(zh, en)
        return label

    def add_scenario(self, name: str, stats_file: str):
        """æ·»åŠ ä¸€ä¸ªæµ‹è¯•åœºæ™¯"""
        with open(stats_file, 'r', encoding='utf-8') as f:
            stats = json.load(f)

        # æå– Round 1 å’Œ Round 2
        round1 = next((s for s in stats if s.get('round_num') == 1), None)
        round2 = next((s for s in stats if s.get('round_num') == 2), None)

        if not round1:
            if len(stats) >= 2:
                round1 = stats[0]
                round2 = stats[1]
            else:
                raise ValueError(f"{name}: ç¼ºå°‘ Round 1 æ•°æ®")

        if not round2:
            raise ValueError(f"{name}: ç¼ºå°‘ Round 2 æ•°æ®")

        # éªŒè¯å¿…éœ€å­—æ®µ
        required_fields = ['avg_ttft', 'avg_tpot', 'request_throughput', 'total_requests']
        missing_fields = [f for f in required_fields if f not in round1]
        if missing_fields:
            raise ValueError(f"{name}: ç»Ÿè®¡æ•°æ®ç¼ºå°‘å­—æ®µ: {missing_fields}")

        self.scenarios.append({
            'name': name,
            'round1': round1,
            'round2': round2
        })

        print(f"âœ“ å·²åŠ è½½åœºæ™¯: {name}")

    def _calculate_metrics(self, scenario: Dict) -> Dict:
        """è®¡ç®—åœºæ™¯çš„å…³é”®æŒ‡æ ‡"""
        round1 = scenario['round1']
        round2 = scenario['round2']

        ttft_baseline = round1['avg_ttft'] * 1000  # ms
        ttft_cached = round2['avg_ttft'] * 1000
        ttft_reduction = (1 - round2['avg_ttft'] / round1['avg_ttft']) * 100

        tpot_baseline = round1['avg_tpot'] * 1000
        tpot_cached = round2['avg_tpot'] * 1000
        tpot_change = ((round2['avg_tpot'] - round1['avg_tpot']) / round1['avg_tpot']) * 100

        throughput_baseline = round1['request_throughput']
        throughput_cached = round2['request_throughput']
        throughput_increase = (round2['request_throughput'] / round1['request_throughput'] - 1) * 100

        token_throughput_baseline = round1.get('token_throughput', 0)
        token_throughput_cached = round2.get('token_throughput', 0)
        token_increase = 0
        if token_throughput_baseline > 0:
            token_increase = (token_throughput_cached / token_throughput_baseline - 1) * 100

        return {
            'ttft_baseline': ttft_baseline,
            'ttft_cached': ttft_cached,
            'ttft_reduction': ttft_reduction,
            'tpot_baseline': tpot_baseline,
            'tpot_cached': tpot_cached,
            'tpot_change': tpot_change,
            'throughput_baseline': throughput_baseline,
            'throughput_cached': throughput_cached,
            'throughput_increase': throughput_increase,
            'token_throughput_baseline': token_throughput_baseline,
            'token_throughput_cached': token_throughput_cached,
            'token_increase': token_increase,
        }

    def _get_cross_node_summary(self) -> str:
        """ç”Ÿæˆè·¨èŠ‚ç‚¹æµ‹è¯•æ±‡æ€»"""
        cross_node_scenarios = []
        single_node_scenarios = []

        for scenario in self.scenarios:
            round1 = scenario['round1']
            round2 = scenario['round2']
            endpoint1 = round1.get('endpoint_url')
            endpoint2 = round2.get('endpoint_url')

            if endpoint1 and endpoint2 and endpoint1 != endpoint2:
                cross_node_scenarios.append({
                    'name': scenario['name'],
                    'node_a': endpoint1,
                    'node_b': endpoint2
                })
            else:
                single_node_scenarios.append(scenario['name'])

        if not cross_node_scenarios:
            return ""

        lines = []
        lines.append("### ğŸŒ è·¨èŠ‚ç‚¹æµ‹è¯•ä¿¡æ¯")
        lines.append("")
        lines.append(f"æœ¬æ¬¡æµ‹è¯•åŒ…å« **{len(cross_node_scenarios)}** ä¸ªè·¨èŠ‚ç‚¹åœºæ™¯ï¼ŒéªŒè¯ Mooncake KV Cache è·¨èŠ‚ç‚¹ä¼ è¾“èƒ½åŠ›ï¼š")
        lines.append("")

        for idx, scenario in enumerate(cross_node_scenarios, 1):
            lines.append(f"{idx}. **{scenario['name']}**")
            lines.append(f"   - èŠ‚ç‚¹ A (å­˜å‚¨ç¼“å­˜): `{scenario['node_a']}`")
            lines.append(f"   - èŠ‚ç‚¹ B (åŠ è½½ç¼“å­˜): `{scenario['node_b']}`")
            lines.append("")

        lines.append("> è·¨èŠ‚ç‚¹æµ‹è¯•è¯´æ˜: Round 1 åœ¨èŠ‚ç‚¹ A æ‰§è¡Œå¹¶å­˜å‚¨ KV Cacheï¼ŒRound 2 åœ¨èŠ‚ç‚¹ B æ‰§è¡Œå¹¶ä»èŠ‚ç‚¹ A åŠ è½½ç¼“å­˜ã€‚")
        lines.append("> TTFT é™ä½å’Œååé‡æå‡è¯´æ˜ Mooncake æˆåŠŸåœ¨èŠ‚ç‚¹é—´ä¼ è¾“äº† KV Cacheã€‚")
        lines.append("")

        return '\n'.join(lines)

    def generate_summary_table(self) -> str:
        """ç”Ÿæˆæ±‡æ€»è¡¨æ ¼ Markdown"""
        lines = []
        lines.append("## ğŸ“Š æµ‹è¯•ç»“æœæ±‡æ€»")
        lines.append("")

        # æ·»åŠ è·¨èŠ‚ç‚¹æµ‹è¯•æ±‡æ€»
        cross_node_summary = self._get_cross_node_summary()
        if cross_node_summary:
            lines.append(cross_node_summary)

        lines.append("### TTFT (é¦– Token å»¶è¿Ÿ)")
        lines.append("")
        lines.append("| æµ‹è¯•åœºæ™¯ | Baseline | Cache Hit | é™ä½ |")
        lines.append("|---------|----------|-----------|------|")

        for scenario in self.scenarios:
            metrics = self._calculate_metrics(scenario)
            status = "âœ…" if metrics['ttft_reduction'] >= 60 else ("âš ï¸" if metrics['ttft_reduction'] >= 40 else "âŒ")

            # æ·»åŠ è·¨èŠ‚ç‚¹æ ‡è¯†
            round1 = scenario['round1']
            round2 = scenario['round2']
            endpoint1 = round1.get('endpoint_url')
            endpoint2 = round2.get('endpoint_url')
            is_cross_node = endpoint1 and endpoint2 and endpoint1 != endpoint2
            name_display = f"ğŸŒ {scenario['name']}" if is_cross_node else scenario['name']

            lines.append(f"| {name_display} | {metrics['ttft_baseline']:.1f} ms | {metrics['ttft_cached']:.1f} ms | {metrics['ttft_reduction']:.1f}% |")

        lines.append("")
        lines.append("### ååé‡ (Throughput)")
        lines.append("")
        lines.append("| æµ‹è¯•åœºæ™¯ | Baseline | Cache Hit | æå‡ |")
        lines.append("|---------|----------|-----------|------|")

        for scenario in self.scenarios:
            metrics = self._calculate_metrics(scenario)
            status = "âœ…" if metrics['throughput_increase'] >= 150 else ("âš ï¸" if metrics['throughput_increase'] >= 100 else "âŒ")

            round1 = scenario['round1']
            round2 = scenario['round2']
            is_cross_node = round1.get('endpoint_url') and round2.get('endpoint_url') and round1.get('endpoint_url') != round2.get('endpoint_url')
            name_display = f"ğŸŒ {scenario['name']}" if is_cross_node else scenario['name']

            lines.append(f"| {name_display} | {metrics['throughput_baseline']:.2f} req/s | {metrics['throughput_cached']:.2f} req/s | +{metrics['throughput_increase']:.1f}% |")

        lines.append("")
        lines.append("### TPOT (æ¯ Token å»¶è¿Ÿ)")
        lines.append("")
        lines.append("| æµ‹è¯•åœºæ™¯ | Baseline | Cache Hit | å˜åŒ– |")
        lines.append("|---------|----------|-----------|------|")

        for scenario in self.scenarios:
            metrics = self._calculate_metrics(scenario)
            status = "âœ…" if abs(metrics['tpot_change']) < 10 else "âš ï¸"

            round1 = scenario['round1']
            round2 = scenario['round2']
            is_cross_node = round1.get('endpoint_url') and round2.get('endpoint_url') and round1.get('endpoint_url') != round2.get('endpoint_url')
            name_display = f"ğŸŒ {scenario['name']}" if is_cross_node else scenario['name']

            lines.append(f"| {name_display} | {metrics['tpot_baseline']:.2f} ms | {metrics['tpot_cached']:.2f} ms | {metrics['tpot_change']:+.1f}% |")

        lines.append("")
        lines.append("### Token ååé‡")
        lines.append("")
        lines.append("| æµ‹è¯•åœºæ™¯ | Baseline | Cache Hit | æå‡ |")
        lines.append("|---------|----------|-----------|------|")

        for scenario in self.scenarios:
            metrics = self._calculate_metrics(scenario)

            round1 = scenario['round1']
            round2 = scenario['round2']
            is_cross_node = round1.get('endpoint_url') and round2.get('endpoint_url') and round1.get('endpoint_url') != round2.get('endpoint_url')
            name_display = f"ğŸŒ {scenario['name']}" if is_cross_node else scenario['name']

            if metrics['token_throughput_baseline'] > 0:
                lines.append(f"| {name_display} | {metrics['token_throughput_baseline']:.1f} tokens/s | {metrics['token_throughput_cached']:.1f} tokens/s | +{metrics['token_increase']:.1f}% |")
            else:
                lines.append(f"| {name_display} | N/A | N/A | N/A |")

        return '\n'.join(lines)

    def generate_detailed_tables(self) -> str:
        """ä¸ºæ¯ä¸ªåœºæ™¯ç”Ÿæˆè¯¦ç»†è¡¨æ ¼"""
        lines = []
        lines.append("## ğŸ“‹ è¯¦ç»†æµ‹è¯•æ•°æ®")
        lines.append("")

        for scenario in self.scenarios:
            lines.append(f"### {scenario['name']}")
            lines.append("")

            round1 = scenario['round1']
            round2 = scenario['round2']
            metrics = self._calculate_metrics(scenario)

            # æ£€æµ‹è·¨èŠ‚ç‚¹æµ‹è¯•
            endpoint1 = round1.get('endpoint_url')
            endpoint2 = round2.get('endpoint_url')
            is_cross_node = endpoint1 and endpoint2 and endpoint1 != endpoint2

            # å¦‚æœæ˜¯è·¨èŠ‚ç‚¹æµ‹è¯•ï¼Œæ˜¾ç¤ºèŠ‚ç‚¹ä¿¡æ¯
            if is_cross_node:
                lines.append("#### ğŸŒ è·¨èŠ‚ç‚¹æµ‹è¯•ä¿¡æ¯")
                lines.append("")
                lines.append(f"- **Round 1 (Baseline)**: èŠ‚ç‚¹ A - `{endpoint1}`")
                lines.append(f"- **Round 2 (Cache Hit)**: èŠ‚ç‚¹ B - `{endpoint2}`")
                lines.append(f"- **KV Cache ä¼ è¾“**: âœ… ä»èŠ‚ç‚¹ A ä¼ è¾“åˆ°èŠ‚ç‚¹ B")
                lines.append("")
            elif endpoint1:
                lines.append(f"**æµ‹è¯•ç«¯ç‚¹**: `{endpoint1}`")
                lines.append("")

            lines.append("| æŒ‡æ ‡ | Baseline (Round 1) | Cache Hit (Round 2) | æ”¹å–„ | ç›®æ ‡ | çŠ¶æ€ |")
            lines.append("|------|-------------------|---------------------|------|------|------|")

            # TTFT
            ttft_status = "âœ…" if metrics['ttft_reduction'] >= 60 else ("âš ï¸" if metrics['ttft_reduction'] >= 40 else "âŒ")
            lines.append(f"| TTFT (avg) | {metrics['ttft_baseline']:.2f} ms | {metrics['ttft_cached']:.2f} ms | -{metrics['ttft_reduction']:.1f}% | -60% | {ttft_status} |")

            # TTFT P90
            if 'p90_ttft' in round1:
                ttft_p90_baseline = round1['p90_ttft'] * 1000
                ttft_p90_cached = round2['p90_ttft'] * 1000
                ttft_p90_reduction = (1 - round2['p90_ttft'] / round1['p90_ttft']) * 100
                lines.append(f"| TTFT (P90) | {ttft_p90_baseline:.2f} ms | {ttft_p90_cached:.2f} ms | -{ttft_p90_reduction:.1f}% | - | - |")

            # TPOT
            tpot_status = "âœ…" if abs(metrics['tpot_change']) < 10 else "âš ï¸"
            lines.append(f"| TPOT (avg) | {metrics['tpot_baseline']:.2f} ms | {metrics['tpot_cached']:.2f} ms | {metrics['tpot_change']:+.1f}% | ç¨³å®š | {tpot_status} |")

            # ååé‡
            throughput_status = "âœ…" if metrics['throughput_increase'] >= 150 else ("âš ï¸" if metrics['throughput_increase'] >= 100 else "âŒ")
            lines.append(f"| ååé‡ (req/s) | {metrics['throughput_baseline']:.2f} | {metrics['throughput_cached']:.2f} | +{metrics['throughput_increase']:.1f}% | +150% | {throughput_status} |")

            # Token ååé‡
            if metrics['token_throughput_baseline'] > 0:
                lines.append(f"| Token ååé‡ | {metrics['token_throughput_baseline']:.1f} tokens/s | {metrics['token_throughput_cached']:.1f} tokens/s | +{metrics['token_increase']:.1f}% | - | - |")

            # ç«¯åˆ°ç«¯å»¶è¿Ÿ
            latency_baseline = round1.get('avg_latency', 0)
            latency_cached = round2.get('avg_latency', 0)
            if latency_baseline > 0:
                latency_change = ((latency_cached - latency_baseline) / latency_baseline) * 100
                lines.append(f"| ç«¯åˆ°ç«¯å»¶è¿Ÿ | {latency_baseline:.2f} s | {latency_cached:.2f} s | {latency_change:+.1f}% | - | - |")

            lines.append("")

        return '\n'.join(lines)

    def generate_comparison_charts(self, output_dir: str = "report_charts") -> List[str]:
        """ç”Ÿæˆå¯¹æ¯”å›¾è¡¨"""
        if not HAS_MATPLOTLIB:
            print("âš ï¸  è·³è¿‡å›¾è¡¨ç”Ÿæˆï¼ˆmatplotlib æœªå®‰è£…ï¼‰")
            return []

        output_path = Path(output_dir)
        output_path.mkdir(exist_ok=True)

        chart_files = []

        # 1. TTFT å¯¹æ¯”å›¾
        chart_files.append(self._generate_ttft_comparison_chart(output_path))

        # 2. ååé‡å¯¹æ¯”å›¾
        chart_files.append(self._generate_throughput_comparison_chart(output_path))

        # 3. TTFT é™ä½ç™¾åˆ†æ¯”å¯¹æ¯”
        chart_files.append(self._generate_ttft_reduction_chart(output_path))

        # 4. ååé‡æå‡ç™¾åˆ†æ¯”å¯¹æ¯”
        chart_files.append(self._generate_throughput_increase_chart(output_path))

        # 5. ç»¼åˆå¯¹æ¯”é›·è¾¾å›¾ï¼ˆå¦‚æœåœºæ™¯ <= 6ï¼‰
        if len(self.scenarios) <= 6:
            chart_files.append(self._generate_radar_chart(output_path))

        return chart_files

    def _generate_ttft_comparison_chart(self, output_path: Path) -> str:
        """ç”Ÿæˆ TTFT å¯¹æ¯”æŸ±çŠ¶å›¾"""
        fig, ax = plt.subplots(figsize=(max(10, len(self.scenarios) * 2), 6))

        x = np.arange(len(self.scenarios))
        width = 0.35

        baseline_values = []
        cached_values = []
        labels = []

        for scenario in self.scenarios:
            metrics = self._calculate_metrics(scenario)
            baseline_values.append(metrics['ttft_baseline'])
            cached_values.append(metrics['ttft_cached'])
            # ç®€åŒ–åœºæ™¯åç§°ï¼ˆå»æ‰å¹³å°å‰ç¼€ï¼Œåªä¿ç•™å…³é”®ä¿¡æ¯ï¼‰
            name = scenario['name']
            if '-' in name:
                parts = name.split('-')
                # å°è¯•ç¼©çŸ­ï¼šå¦‚ "è…¾è®¯äº‘-72B-å•èŠ‚ç‚¹-å¤šè½®" -> "72B-Single-Multi"
                if len(parts) >= 4:
                    # æ ¼å¼: äº‘å¹³å°-æ¨¡å‹-éƒ¨ç½²æ–¹å¼-åœºæ™¯ç±»å‹
                    label = f"{parts[1]}-{parts[2]}-{parts[3]}"
                    labels.append(self._translate_label(label))
                elif len(parts) >= 3:
                    label = f"{parts[1]}-{parts[2]}"
                    labels.append(self._translate_label(label))
                else:
                    labels.append(self._translate_label(name))
            else:
                labels.append(self._translate_label(name))

        bars1 = ax.bar(x - width/2, baseline_values, width, label='Baseline', color='#e74c3c', alpha=0.8)
        bars2 = ax.bar(x + width/2, cached_values, width, label='Cache Hit', color='#2ecc71', alpha=0.8)

        ax.set_ylabel('TTFT (ms)', fontsize=12, fontweight='bold')
        ax.set_title('TTFT Comparison - Multi Scenarios', fontsize=14, fontweight='bold')
        ax.set_xticks(x)
        ax.set_xticklabels(labels, rotation=45, ha='right')
        ax.legend()
        ax.grid(True, alpha=0.3, axis='y')

        # æ·»åŠ æ•°å€¼æ ‡ç­¾
        for bar in bars1:
            height = bar.get_height()
            ax.text(bar.get_x() + bar.get_width()/2., height,
                    f'{height:.0f}',
                    ha='center', va='bottom', fontsize=9)

        for bar in bars2:
            height = bar.get_height()
            ax.text(bar.get_x() + bar.get_width()/2., height,
                    f'{height:.0f}',
                    ha='center', va='bottom', fontsize=9)

        chart_file = output_path / "ttft_comparison.png"
        plt.tight_layout()
        plt.savefig(chart_file, dpi=150, bbox_inches='tight')
        plt.close()

        return str(chart_file)

    def _generate_throughput_comparison_chart(self, output_path: Path) -> str:
        """ç”Ÿæˆååé‡å¯¹æ¯”æŸ±çŠ¶å›¾"""
        fig, ax = plt.subplots(figsize=(max(10, len(self.scenarios) * 2), 6))

        x = np.arange(len(self.scenarios))
        width = 0.35

        baseline_values = []
        cached_values = []
        labels = []

        for scenario in self.scenarios:
            metrics = self._calculate_metrics(scenario)
            baseline_values.append(metrics['throughput_baseline'])
            cached_values.append(metrics['throughput_cached'])
            name = scenario['name']
            if '-' in name:
                parts = name.split('-')
                if len(parts) >= 4:
                    label = f"{parts[1]}-{parts[2]}-{parts[3]}"
                    labels.append(self._translate_label(label))
                elif len(parts) >= 3:
                    label = f"{parts[1]}-{parts[2]}"
                    labels.append(self._translate_label(label))
                else:
                    labels.append(self._translate_label(name))
            else:
                labels.append(self._translate_label(name))

        bars1 = ax.bar(x - width/2, baseline_values, width, label='Baseline', color='#3498db', alpha=0.8)
        bars2 = ax.bar(x + width/2, cached_values, width, label='Cache Hit', color='#f39c12', alpha=0.8)

        ax.set_ylabel('Throughput (req/s)', fontsize=12, fontweight='bold')
        ax.set_title('Throughput Comparison - Multi Scenarios', fontsize=14, fontweight='bold')
        ax.set_xticks(x)
        ax.set_xticklabels(labels, rotation=45, ha='right')
        ax.legend()
        ax.grid(True, alpha=0.3, axis='y')

        for bar in bars1:
            height = bar.get_height()
            ax.text(bar.get_x() + bar.get_width()/2., height,
                    f'{height:.1f}',
                    ha='center', va='bottom', fontsize=9)

        for bar in bars2:
            height = bar.get_height()
            ax.text(bar.get_x() + bar.get_width()/2., height,
                    f'{height:.1f}',
                    ha='center', va='bottom', fontsize=9)

        chart_file = output_path / "throughput_comparison.png"
        plt.tight_layout()
        plt.savefig(chart_file, dpi=150, bbox_inches='tight')
        plt.close()

        return str(chart_file)

    def _generate_ttft_reduction_chart(self, output_path: Path) -> str:
        """ç”Ÿæˆ TTFT é™ä½ç™¾åˆ†æ¯”å›¾"""
        fig, ax = plt.subplots(figsize=(max(10, len(self.scenarios) * 1.5), 6))

        labels = []
        reductions = []
        colors = []

        for scenario in self.scenarios:
            metrics = self._calculate_metrics(scenario)
            name = scenario['name']
            if '-' in name:
                parts = name.split('-')
                if len(parts) >= 4:
                    label = f"{parts[1]}-{parts[2]}-{parts[3]}"
                    labels.append(self._translate_label(label))
                elif len(parts) >= 3:
                    label = f"{parts[1]}-{parts[2]}"
                    labels.append(self._translate_label(label))
                else:
                    labels.append(self._translate_label(name))
            else:
                labels.append(self._translate_label(name))

            reductions.append(metrics['ttft_reduction'])
            # æ ¹æ®æ•ˆæœè®¾ç½®é¢œè‰²
            if metrics['ttft_reduction'] >= 60:
                colors.append('#2ecc71')  # ç»¿è‰² - ä¼˜ç§€
            elif metrics['ttft_reduction'] >= 40:
                colors.append('#f39c12')  # æ©™è‰² - ä¸€èˆ¬
            else:
                colors.append('#e74c3c')  # çº¢è‰² - ä¸ç†æƒ³

        y_pos = np.arange(len(labels))
        bars = ax.barh(y_pos, reductions, color=colors, alpha=0.8)

        ax.set_xlabel('TTFT Reduction (%)', fontsize=12, fontweight='bold')
        ax.set_title('TTFT Reduction Comparison', fontsize=14, fontweight='bold')
        ax.set_yticks(y_pos)
        ax.set_yticklabels(labels)
        ax.axvline(x=60, color='green', linestyle='--', linewidth=2, alpha=0.7, label='Target: 60%')
        ax.legend()
        ax.grid(True, alpha=0.3, axis='x')

        for i, bar in enumerate(bars):
            width = bar.get_width()
            ax.text(width, bar.get_y() + bar.get_height()/2.,
                    f' {width:.1f}%',
                    ha='left', va='center', fontsize=10, fontweight='bold')

        chart_file = output_path / "ttft_reduction_comparison.png"
        plt.tight_layout()
        plt.savefig(chart_file, dpi=150, bbox_inches='tight')
        plt.close()

        return str(chart_file)

    def _generate_throughput_increase_chart(self, output_path: Path) -> str:
        """ç”Ÿæˆååé‡æå‡ç™¾åˆ†æ¯”å›¾"""
        fig, ax = plt.subplots(figsize=(max(10, len(self.scenarios) * 1.5), 6))

        labels = []
        increases = []
        colors = []

        for scenario in self.scenarios:
            metrics = self._calculate_metrics(scenario)
            name = scenario['name']
            if '-' in name:
                parts = name.split('-')
                if len(parts) >= 4:
                    label = f"{parts[1]}-{parts[2]}-{parts[3]}"
                    labels.append(self._translate_label(label))
                elif len(parts) >= 3:
                    label = f"{parts[1]}-{parts[2]}"
                    labels.append(self._translate_label(label))
                else:
                    labels.append(self._translate_label(name))
            else:
                labels.append(self._translate_label(name))

            increases.append(metrics['throughput_increase'])
            if metrics['throughput_increase'] >= 150:
                colors.append('#2ecc71')
            elif metrics['throughput_increase'] >= 100:
                colors.append('#f39c12')
            else:
                colors.append('#e74c3c')

        y_pos = np.arange(len(labels))
        bars = ax.barh(y_pos, increases, color=colors, alpha=0.8)

        ax.set_xlabel('Throughput Increase (%)', fontsize=12, fontweight='bold')
        ax.set_title('Throughput Increase Comparison', fontsize=14, fontweight='bold')
        ax.set_yticks(y_pos)
        ax.set_yticklabels(labels)
        ax.axvline(x=150, color='green', linestyle='--', linewidth=2, alpha=0.7, label='Target: 150%')
        ax.legend()
        ax.grid(True, alpha=0.3, axis='x')

        for i, bar in enumerate(bars):
            width = bar.get_width()
            ax.text(width, bar.get_y() + bar.get_height()/2.,
                    f' +{width:.1f}%',
                    ha='left', va='center', fontsize=10, fontweight='bold')

        chart_file = output_path / "throughput_increase_comparison.png"
        plt.tight_layout()
        plt.savefig(chart_file, dpi=150, bbox_inches='tight')
        plt.close()

        return str(chart_file)

    def _generate_radar_chart(self, output_path: Path) -> str:
        """ç”Ÿæˆé›·è¾¾å›¾ï¼ˆç»¼åˆå¯¹æ¯”ï¼‰"""
        # å½’ä¸€åŒ–æŒ‡æ ‡ï¼šTTFTé™ä½ã€ååé‡æå‡ã€TPOTç¨³å®šæ€§
        fig, ax = plt.subplots(figsize=(10, 10), subplot_kw=dict(projection='polar'))

        # ä¸‰ä¸ªç»´åº¦
        categories = ['TTFT\né™ä½', 'ååé‡\næå‡', 'TPOT\nç¨³å®šæ€§']
        N = len(categories)

        angles = [n / float(N) * 2 * np.pi for n in range(N)]
        angles += angles[:1]

        ax.set_theta_offset(np.pi / 2)
        ax.set_theta_direction(-1)
        ax.set_xticks(angles[:-1])
        ax.set_xticklabels(['TTFT\nReduction', 'Throughput\nIncrease', 'TPOT\nStability'], fontsize=11)

        # ä¸ºæ¯ä¸ªåœºæ™¯ç»˜åˆ¶é›·è¾¾å›¾
        colors = plt.cm.Set3(np.linspace(0, 1, len(self.scenarios)))

        for idx, scenario in enumerate(self.scenarios):
            metrics = self._calculate_metrics(scenario)

            # å½’ä¸€åŒ–åˆ†æ•°ï¼ˆ0-100ï¼‰
            ttft_score = min(100, (metrics['ttft_reduction'] / 60) * 100)
            throughput_score = min(100, (metrics['throughput_increase'] / 150) * 100)
            tpot_score = max(0, 100 - abs(metrics['tpot_change']) * 10)  # å˜åŒ–è¶Šå°åˆ†æ•°è¶Šé«˜

            values = [ttft_score, throughput_score, tpot_score]
            values += values[:1]

            # ç®€åŒ–æ ‡ç­¾
            name = scenario['name']
            if '-' in name:
                parts = name.split('-')
                if len(parts) >= 4:
                    label = f"{parts[1]}-{parts[2]}-{parts[3]}"
                    label = self._translate_label(label)
                elif len(parts) >= 3:
                    label = f"{parts[1]}-{parts[2]}"
                    label = self._translate_label(label)
                else:
                    label = self._translate_label(name)
            else:
                label = self._translate_label(name)

            ax.plot(angles, values, 'o-', linewidth=2, label=label, color=colors[idx])
            ax.fill(angles, values, alpha=0.15, color=colors[idx])

        ax.set_ylim(0, 100)
        ax.set_yticks([20, 40, 60, 80, 100])
        ax.set_yticklabels(['20', '40', '60', '80', '100'], fontsize=9)
        ax.grid(True)

        plt.legend(loc='upper right', bbox_to_anchor=(1.3, 1.1), fontsize=9)
        plt.title('Performance Comparison (Radar Chart)', size=14, fontweight='bold', y=1.08)

        chart_file = output_path / "performance_radar.png"
        plt.tight_layout()
        plt.savefig(chart_file, dpi=150, bbox_inches='tight')
        plt.close()

        return str(chart_file)

    def generate_full_report(self, output_file: str = None, chart_dir: str = "report_charts") -> str:
        """ç”Ÿæˆå®Œæ•´æŠ¥å‘Š"""
        if not output_file:
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            output_file = f"multi_scenario_report_{timestamp}.md"

        lines = []

        # æ ‡é¢˜
        lines.append("# Mooncake KV Cache å¤šåœºæ™¯æ€§èƒ½æµ‹è¯•æŠ¥å‘Š")
        lines.append("")
        lines.append(f"**æŠ¥å‘Šæ—¥æœŸ**: {datetime.now().strftime('%Yå¹´%mæœˆ%dæ—¥')}")
        lines.append(f"**æµ‹è¯•åœºæ™¯æ•°**: {len(self.scenarios)}")
        lines.append("")
        lines.append("---")
        lines.append("")

        # æ±‡æ€»è¡¨æ ¼
        lines.append(self.generate_summary_table())
        lines.append("")
        lines.append("---")
        lines.append("")

        # ç”Ÿæˆå›¾è¡¨
        print("\nğŸ“Š ç”Ÿæˆå¯¹æ¯”å›¾è¡¨...")
        chart_files = self.generate_comparison_charts(chart_dir)

        if chart_files:
            lines.append("## ğŸ“ˆ å¯è§†åŒ–å¯¹æ¯”")
            lines.append("")
            for chart in chart_files:
                chart_name = Path(chart).name
                lines.append(f"### {chart_name.replace('_', ' ').replace('.png', '').title()}")
                lines.append("")
                lines.append(f"![{chart_name}]({chart})")
                lines.append("")
            lines.append("---")
            lines.append("")

        # è¯¦ç»†è¡¨æ ¼
        lines.append(self.generate_detailed_tables())
        lines.append("")
        lines.append("---")
        lines.append("")

        # æ€»ç»“
        lines.append("## ğŸ’¡ æµ‹è¯•æ€»ç»“")
        lines.append("")

        success_count = 0
        partial_count = 0
        fail_count = 0

        for scenario in self.scenarios:
            metrics = self._calculate_metrics(scenario)
            if metrics['ttft_reduction'] >= 60 and metrics['throughput_increase'] >= 150:
                success_count += 1
            elif metrics['ttft_reduction'] >= 40 or metrics['throughput_increase'] >= 100:
                partial_count += 1
            else:
                fail_count += 1

        lines.append(f"- **âœ… ä¼˜ç§€åœºæ™¯**: {success_count}/{len(self.scenarios)} (æ‰€æœ‰æŒ‡æ ‡è¾¾æ ‡)")
        lines.append(f"- **âš ï¸ è‰¯å¥½åœºæ™¯**: {partial_count}/{len(self.scenarios)} (éƒ¨åˆ†æŒ‡æ ‡è¾¾æ ‡)")
        lines.append(f"- **âŒ å¾…ä¼˜åŒ–åœºæ™¯**: {fail_count}/{len(self.scenarios)} (éœ€è¦ä¼˜åŒ–)")
        lines.append("")

        if success_count == len(self.scenarios):
            lines.append("**ç»“è®º**: æ‰€æœ‰æµ‹è¯•åœºæ™¯å‡è¾¾åˆ°é¢„æœŸç›®æ ‡ï¼ŒMooncake KV Cache æ€§èƒ½è¡¨ç°ä¼˜ç§€ã€‚")
        elif success_count + partial_count == len(self.scenarios):
            lines.append("**ç»“è®º**: å¤§éƒ¨åˆ†åœºæ™¯è¾¾åˆ°é¢„æœŸï¼Œéƒ¨åˆ†åœºæ™¯æœ‰ä¼˜åŒ–ç©ºé—´ï¼Œå»ºè®®é’ˆå¯¹æ€§è°ƒä¼˜ã€‚")
        else:
            lines.append("**ç»“è®º**: éƒ¨åˆ†åœºæ™¯æœªè¾¾é¢„æœŸï¼Œéœ€è¦æ’æŸ¥é…ç½®å’Œç¯å¢ƒé—®é¢˜ã€‚")

        lines.append("")
        lines.append("---")
        lines.append("")
        lines.append(f"**æŠ¥å‘Šç”Ÿæˆæ—¶é—´**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")

        # å†™å…¥æ–‡ä»¶
        with open(output_file, 'w', encoding='utf-8') as f:
            f.write('\n'.join(lines))

        print(f"\nâœ… æŠ¥å‘Šå·²ç”Ÿæˆ: {output_file}")
        if chart_files:
            print(f"âœ… å›¾è¡¨å·²ç”Ÿæˆ: {len(chart_files)} ä¸ªæ–‡ä»¶åœ¨ {chart_dir}/ ç›®å½•")

        return output_file


def main():
    parser = argparse.ArgumentParser(
        description="å¤šåœºæ™¯æµ‹è¯•ç»“æœæ±‡æ€»å’ŒæŠ¥å‘Šç”Ÿæˆ",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ç¤ºä¾‹ç”¨æ³•:

1. å•ä¸ªåœºæ™¯:
   python3 generate_multi_scenario_report.py \\
       --scenario "è…¾è®¯äº‘-å•æœº-Qwen2.5-72B" \\
       --stats test_results/qwen_single_stats.json

2. å¤šä¸ªåœºæ™¯:
   python3 generate_multi_scenario_report.py \\
       --scenario "è…¾è®¯äº‘-å•æœº-Qwen2.5-72B" --stats test_results/qwen_single_stats.json \\
       --scenario "è…¾è®¯äº‘-è·¨èŠ‚ç‚¹-Qwen2.5-72B" --stats test_results/qwen_cross_stats.json \\
       --scenario "ç«å±±äº‘-å•æœº-Deepseek-R1" --stats test_results/deepseek_stats.json \\
       --output final_report.md \\
       --chart-dir charts

3. ä½¿ç”¨é€šé…ç¬¦æ‰¹é‡åŠ è½½ï¼ˆéœ€è¦åœºæ™¯ååŒ…å«åœ¨æ–‡ä»¶åä¸­ï¼‰:
   python3 generate_multi_scenario_report.py \\
       --auto-load test_results/*_stats.json \\
       --output report.md
        """
    )

    parser.add_argument('--scenario', action='append', dest='scenario_names',
                        help='æµ‹è¯•åœºæ™¯åç§°ï¼ˆå¯å¤šæ¬¡ä½¿ç”¨ï¼‰')
    parser.add_argument('--stats', action='append', dest='stats_files',
                        help='å¯¹åº”çš„ç»Ÿè®¡æ–‡ä»¶è·¯å¾„ï¼ˆä¸ --scenario é…å¯¹ï¼‰')
    parser.add_argument('--output', type=str,
                        help='è¾“å‡ºæŠ¥å‘Šæ–‡ä»¶åï¼ˆé»˜è®¤: multi_scenario_report_<timestamp>.mdï¼‰')
    parser.add_argument('--chart-dir', type=str, default='report_charts',
                        help='å›¾è¡¨è¾“å‡ºç›®å½•ï¼ˆé»˜è®¤: report_chartsï¼‰')
    parser.add_argument('--no-charts', action='store_true',
                        help='ä¸ç”Ÿæˆå›¾è¡¨ï¼ˆä»…ç”Ÿæˆè¡¨æ ¼ï¼‰')

    args = parser.parse_args()

    # éªŒè¯å‚æ•°
    if not args.scenario_names or not args.stats_files:
        print("âŒ é”™è¯¯: å¿…é¡»æä¾› --scenario å’Œ --stats å‚æ•°")
        print("ç¤ºä¾‹: --scenario \"è…¾è®¯äº‘-Qwen2.5\" --stats test_stats.json")
        parser.print_help()
        sys.exit(1)

    if len(args.scenario_names) != len(args.stats_files):
        print("âŒ é”™è¯¯: --scenario å’Œ --stats å‚æ•°æ•°é‡å¿…é¡»ä¸€è‡´")
        sys.exit(1)

    print("="*80)
    print("ğŸ“Š å¤šåœºæ™¯æµ‹è¯•æŠ¥å‘Šç”Ÿæˆå·¥å…·")
    print("="*80)

    try:
        reporter = MultiScenarioReporter()

        # åŠ è½½æ‰€æœ‰åœºæ™¯
        for name, stats_file in zip(args.scenario_names, args.stats_files):
            reporter.add_scenario(name, stats_file)

        # ç”ŸæˆæŠ¥å‘Š
        print(f"\nğŸ“ ç”ŸæˆæŠ¥å‘Š...")
        if args.no_charts:
            # ä»…ç”Ÿæˆè¡¨æ ¼ï¼Œä¸ç”Ÿæˆå›¾è¡¨
            output_file = args.output or f"multi_scenario_report_{datetime.now().strftime('%Y%m%d_%H%M%S')}.md"

            lines = []
            lines.append("# Mooncake KV Cache å¤šåœºæ™¯æ€§èƒ½æµ‹è¯•æŠ¥å‘Š")
            lines.append("")
            lines.append(f"**æŠ¥å‘Šæ—¥æœŸ**: {datetime.now().strftime('%Yå¹´%mæœˆ%dæ—¥')}")
            lines.append("")
            lines.append("---")
            lines.append("")
            lines.append(reporter.generate_summary_table())
            lines.append("")
            lines.append("---")
            lines.append("")
            lines.append(reporter.generate_detailed_tables())

            with open(output_file, 'w', encoding='utf-8') as f:
                f.write('\n'.join(lines))

            print(f"\nâœ… æŠ¥å‘Šå·²ç”Ÿæˆ: {output_file}")
        else:
            reporter.generate_full_report(args.output, args.chart_dir)

        print("\nâœ… å®Œæˆ!")

    except FileNotFoundError as e:
        print(f"\nâŒ æ–‡ä»¶æœªæ‰¾åˆ°: {e}")
        sys.exit(1)
    except ValueError as e:
        print(f"\nâŒ æ•°æ®é”™è¯¯: {e}")
        sys.exit(1)
    except Exception as e:
        print(f"\nâŒ ç”Ÿæˆå¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        sys.exit(1)


if __name__ == "__main__":
    main()
